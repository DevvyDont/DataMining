{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1ff5253",
   "metadata": {},
   "source": [
    "## Assignment - A3.part2\n",
    "### Devin Hall, Tyler Birnie\n",
    "### Due: 3-25-22 @ 11:59pm\n",
    "Some pre-requisites we will need for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1379abb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca4e54a8",
   "metadata": {},
   "source": [
    "### Question 1: Pokemon Data\n",
    "Load in the data, look at the distribution of Pokemon skills (data features) we will use for dimenionality reduction. \"HP, Attack, Defense, SpAtk, SpDef, and Speed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f4399f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3b34c16",
   "metadata": {},
   "source": [
    "#### Question 1A:\n",
    "create a violin plot showing the distribution of these variables\n",
    "Helpful functions: python- seaborn package; violinplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc13e646",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f13e1637",
   "metadata": {},
   "source": [
    "#### Question 1B: \n",
    "The six features (Pokemon Skills) have different ranges, therefore we should scale the data before considering PCA. Standardize the data (center the data- subtract the mean, and divide by the standard deviation). \n",
    "\n",
    "_\"Note, we only need to scale the data for the 6 variables under consideration\"_\n",
    "Helpful functions: python- StandardScaler from sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c31750cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## use StandardScaler from sklearn.preprocessing to standardize the data \n",
    "# of the 6 variables of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54e5f5f",
   "metadata": {},
   "source": [
    "#### Quesetion 1C:\n",
    "Preform principle components analysis (PCA) on the scaled Pokemon skills data. \n",
    "Helpful funcitons: PCA function sklearn.decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b62e2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7cfba1cc",
   "metadata": {},
   "source": [
    "#### Question 1D:\n",
    "Plot the transformed data in the space defined by the first two principal components.  \n",
    "\n",
    "[This should be a scatter plot]\n",
    "helpful functions: python- matplotlib, scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70e9bdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1dd2cea",
   "metadata": {},
   "source": [
    "#### Question 1E:\n",
    "Explore the amount of variance explained by each principle component direction. \n",
    "First, plot the proportion of variance explained (y-axis) vs. the different principle components. \n",
    "Second, plot the cummulative proportion of variance explained y the principle components. Make sure this plot has y-limits from 0 - 1.\n",
    "helpful functions: python- matplotlib, scatter or plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd19d35e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab8c7935",
   "metadata": {},
   "source": [
    "### Question 2: College Data\n",
    "The set of colleges considered are the 21 top colleges based on earning potential of undergraduates with computer science degrees: \"college_data.csv\" (Sources: 2014- Payscale.com and the National Center for Education Statistics, NCES)\n",
    "[load the data from college_data.csv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4abddc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de60fc33",
   "metadata": {},
   "source": [
    "#### Question 2A:\n",
    "Preform principal component analysis on the college data (make sure to preprare the data in any way needed)\n",
    "Helpful functions: python- PCA from sklearn.decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70981b0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e8bba59",
   "metadata": {},
   "source": [
    "#### Questiton 2B:\n",
    "Plot the dat in the space defined by the first two principal components (labeling each point with the school it represents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2163c7ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8eb2e98",
   "metadata": {},
   "source": [
    "#### Quesiton 2C:\n",
    "Plot the amount of cumulative variance explained.\n",
    "How many principal components should be used for any further analysis to be done on the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c759ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7132d82",
   "metadata": {},
   "source": [
    "### Question 3: Text Classification\n",
    "For this question you will be considering text classificatoin using two different Naive Bayes models. These approaches will be discussed in class and referenced from the following book.\n",
    "\n",
    "Manning, C., Raghavan, P., Schutze, H. Introduction to Information Retrieval, Cambridge University Press, 2008\n",
    "http://nlp.stanford.edu/IR-book/\n",
    "\n",
    "In particular, look at Chapter 13 http://nlp.stanford.edu/IR-book/html/htmledition/text-classification-and-naive-bayes-1.html\n",
    "\n",
    "You will be using data from the Presidential State of the Union Addresses available as a zip archive. The speeches are available in text files sorted by year, e.g., a1.txt, ..., a231.txt. The text files are formated such that there is one word per line and most punctuation has been removed. Note, there are still hyphens or dashes left in the text files and there may be some errors in splitting of words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd867c0d",
   "metadata": {},
   "source": [
    "#### Quesiton 3A:\n",
    "Load the addresses. You will need to create a vector listing the party affiliation of each president to match their speech, you may use the file \"party.txt\" to help with this classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae257ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c8a802f",
   "metadata": {},
   "source": [
    "#### Question 3B:\n",
    "Remove _stopwords_ from consideration for the method. The stopwords are availabe at \"stopwords.txt\" or found in various packages nltk and 'tm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048df746",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "250f3760",
   "metadata": {},
   "source": [
    "#### Question 3C:\n",
    "Predict the part affiliations (Democrat / Republican) for the following speeches:\n",
    "- Donald Trump, 2017\n",
    "- Barrack Obama, 2014\n",
    "- George W. Bush, 2006\n",
    "- William Clinton, 1995\n",
    "- John F. Kennedy, 1962"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d058bec",
   "metadata": {},
   "source": [
    "The training set will be the rmaining speeches that can be associated with the Democratic or Republican presidents(note, you will not need all the addresses, but they were included here for completness of the data). You will need to complete the following steps:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8c4188",
   "metadata": {},
   "source": [
    "##### Question 3Ci:\n",
    "Create a term-document matrix, T D for this set of speeches. Restrict this matrix to the 3000 most frequently used words over all the speeches (not including the stopwords already removed). Show the first 10 rows and 5 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433d36ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "694b46c2",
   "metadata": {},
   "source": [
    "##### Question 3Cii:\n",
    "or the 5 speeches listed above determine the party affiliations of the\n",
    "president. Calculate and report P (C = Dems |X) and P (C = Reb |X) under the Bernoulli model of Na ̈ıve Bayes. \n",
    "Helpful functions: sklearn.naive bayes.BernoulliNB in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7bbea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb6ff5dc",
   "metadata": {},
   "source": [
    "##### Question 3Ciii:\n",
    "For the 5 speeches listed above determine the party affiliations of the\n",
    "president. Calculate and report P (C = Dems |X) and P (C = Reb |X) under the Multinomial model of Na ̈ıve Bayes.\n",
    "Helpful functions: sklearn.naive bayes.MultinomialNB in Python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f6d85e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bdf0448e",
   "metadata": {},
   "source": [
    "##### Question 3Civ:\n",
    "Create a plot showing the top 20 most frequenctly used words across all the Republican and Decmocrate presidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed84421a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5a5ce05",
   "metadata": {},
   "source": [
    "##### Question 3Cv:\n",
    "Create a plot showing the top 10 most frequently used words for Republicans and Democrats in a small multiple or faceted plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9d4452",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8666baa",
   "metadata": {},
   "source": [
    "### Question 4: Text Classification - Bonus\n",
    "Repeat the analysis from above, but implement the Bernoulli Naive Bayes and Multinomial Naive Bayes models yourself. Follow the pseudocode given in the the IR book. Note,for this question you will not use the standard Na ̈ıve Bayes package, library or function.\n",
    "This means you can’t use sklearn.naive bayes.BernoulliNB in Python\n",
    "You can’t use sklearn.naive bayes.MultinomialNB in Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e984c73",
   "metadata": {},
   "source": [
    "#### Question 4A: \n",
    "For the 5 speeches listed above determine the party affiliations of\n",
    "the president. Calculate and report P (C = Dems |X) and P (C = Reb |X) under the Bernoulli model of Na ̈ıve Bayes. In order to avoid underflow errors, use the log probabilities as discussed in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dee108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "509cd485",
   "metadata": {},
   "source": [
    "#### Question 4B: \n",
    "For the 5 speeches listed above determine the party affiliations of the\n",
    "president. Calculate and report P (C = Dems |X) and P (C = Reb |X) under the Multinomial model of Na ̈ıve Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c424a8c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a5c6579",
   "metadata": {},
   "source": [
    "Hint: A strong suggestion for this question is to first create and test your code on a small document set, e.g., the example in the IR-book. Once you have that working correctly, then run on the SOTU addresses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
