{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d1d2c09",
   "metadata": {},
   "source": [
    "## Assignment - A2.part2\n",
    "### Devin Hall, Tyler Birnie\n",
    "### Due: 3-2-22 @ 11:59pm\n",
    "Some pre-requisites we will need for this project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a7dae07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import math as m\n",
    "import matplotlib\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# Here we define the data set used for questions 1 and 2 as a 2D matrix, with each row being sample #, Ytrue, Ypred\n",
    "QUESTION_1_2_DATA = (\n",
    "    [1, True, 0.98],\n",
    "    [2, True, 0.92],\n",
    "    [3, False, 0.87],\n",
    "    [4, True, 0.76],\n",
    "    [5, False, 0.74],\n",
    "    [6, False, 0.61],\n",
    "    [7, True, 0.57],\n",
    "    [8, True, 0.38],\n",
    "    [9, False, 0.34],\n",
    "    [10, False, 0.32],\n",
    ")\n",
    "\n",
    "# Some enums to make array indexing more readable\n",
    "SAMPLE_COLUMN = 0\n",
    "YTRUE_COLUMN = 1\n",
    "YPRED_COLUMN = 2\n",
    "\n",
    "# A helper class to reduce chance of human error when dealing with confusion matrix data set\n",
    "class ConfusionMatrixResult:\n",
    "    def __init__(self, tp, fp, tn, fn):\n",
    "        self.true_positives = tp\n",
    "        self.false_positives = fp\n",
    "        self.true_negatives = tn\n",
    "        self.false_negatives = fn\n",
    "\n",
    "\n",
    "# A helper function to take in a 2D array structured like above, and return # of true positives, false positives, true negatives, false negatives at a certain threshold\n",
    "# contained as a ConfusionMatrixResult\n",
    "def get_confusion_matrix(data, threshold) -> ConfusionMatrixResult:\n",
    "\n",
    "    # setup the counts of the confusion matrix\n",
    "    true_pos = 0\n",
    "    false_pos = 0\n",
    "    true_neg = 0\n",
    "    false_neg = 0\n",
    "\n",
    "    # Loop through all the data\n",
    "    for row in data:\n",
    "        # Extract the data\n",
    "        sample_num: int = row[SAMPLE_COLUMN]\n",
    "        actual_state: bool = row[YTRUE_COLUMN]\n",
    "        predicted_state: float = row[YPRED_COLUMN]\n",
    "\n",
    "        # Does this data fit in the threshold? i.e. is the predicted state >= threshold we defined\n",
    "        in_threshold = predicted_state >= threshold\n",
    "\n",
    "        # First consider the samples that are actually positive, (actual_state == True)\n",
    "        if actual_state:\n",
    "\n",
    "            # Is this in the threshold? i.e., did we make a correct prediction?\n",
    "            if in_threshold:\n",
    "                true_pos += 1  # This is a true positive\n",
    "            else:\n",
    "                false_neg += 1  # Our prediction was wrong, this will be marked as a false negative\n",
    "\n",
    "        else:\n",
    "            # Consider samples that are not positive, (actual_state == False)\n",
    "            # If it isn't in the threshold, that means we guessed correctly that it is negative\n",
    "            if not in_threshold:\n",
    "                true_neg += 1  # This is a true negative\n",
    "            else:\n",
    "                false_pos += 1  # Our prediction was wrong, we thought this was going to be positive but it wasn't\n",
    "\n",
    "    # Now that we looped through all the data, let's return the confusion matrix\n",
    "    return ConfusionMatrixResult(tp=true_pos, fp=false_pos, tn=true_neg, fn=false_neg)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "e2b7a1e7",
   "metadata": {},
   "source": [
    "## (Question 1) For the following data set, compute the:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d6581d",
   "metadata": {},
   "source": [
    "### 1.a: \n",
    "True positive rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f862f5dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "    Threshold  TPR\n1        0.98  0.2\n2        0.92  0.4\n3        0.87  0.4\n4        0.76  0.6\n5        0.74  0.6\n6        0.61  0.6\n7        0.57  0.8\n8        0.38  1.0\n9        0.34  1.0\n10       0.32  1.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Threshold</th>\n      <th>TPR</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.98</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.92</td>\n      <td>0.4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.87</td>\n      <td>0.4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.76</td>\n      <td>0.6</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.74</td>\n      <td>0.6</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.61</td>\n      <td>0.6</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.57</td>\n      <td>0.8</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.38</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.34</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.32</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's get the confusion matrices of 10 thresholds using the prediction values\n",
    "# Use list comprehension to generate a list of all the pred columns for every row in the data\n",
    "THRESHOLDS = [row[YPRED_COLUMN] for row in QUESTION_1_2_DATA]\n",
    "\n",
    "# Now let's make a 2D array that we are going to print for the answer\n",
    "_1a_ans = []\n",
    "\n",
    "# Loop through all the different thresholds we want to use\n",
    "for thresh in THRESHOLDS:\n",
    "    # retrieve the confusion matrix using this threshold\n",
    "    confusion_matrix = get_confusion_matrix(QUESTION_1_2_DATA, thresh)\n",
    "\n",
    "    # TPR is true positives / (true positives + false negatives)\n",
    "    tpr = float(confusion_matrix.true_positives) / float(confusion_matrix.true_positives + confusion_matrix.false_negatives)\n",
    "\n",
    "    # Add this entry to the data we want to display in the format: [threshold, TPR]\n",
    "    _1a_ans.append([thresh, tpr])\n",
    "\n",
    "# Now display the data\n",
    "cols = ['Threshold', 'TPR']\n",
    "rows = [str(i+1) for i in range(10)]\n",
    "pd.DataFrame(np.asarray(_1a_ans), index=rows, columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2022299",
   "metadata": {},
   "source": [
    "### 1.b: \n",
    "False postive rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "89de6d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "    Threshold  FPR\n1        0.98  0.0\n2        0.92  0.0\n3        0.87  0.2\n4        0.76  0.2\n5        0.74  0.4\n6        0.61  0.6\n7        0.57  0.6\n8        0.38  0.6\n9        0.34  0.8\n10       0.32  1.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Threshold</th>\n      <th>FPR</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.98</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.92</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.87</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.76</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.74</td>\n      <td>0.4</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.61</td>\n      <td>0.6</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.57</td>\n      <td>0.6</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.38</td>\n      <td>0.6</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.34</td>\n      <td>0.8</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.32</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note, this is essentially copied from 1a with one modified line\n",
    "# Let's get the confusion matrices of 10 thresholds using the prediction values\n",
    "# Use list comprehension to generate a list of all the pred columns for every row in the data\n",
    "THRESHOLDS = [row[YPRED_COLUMN] for row in QUESTION_1_2_DATA]\n",
    "\n",
    "# Now let's make a 2D array that we are going to print for the answer\n",
    "_1b_ans = []\n",
    "\n",
    "# Loop through all the different thresholds we want to use\n",
    "for thresh in THRESHOLDS:\n",
    "    # retrieve the confusion matrix using this threshold\n",
    "    confusion_matrix = get_confusion_matrix(QUESTION_1_2_DATA, thresh)\n",
    "\n",
    "    # FPR is false positives / (false positives + true negatives)\n",
    "    fpr = float(confusion_matrix.false_positives) / float(confusion_matrix.false_positives + confusion_matrix.true_negatives)\n",
    "\n",
    "    # Add this entry to the data we want to display in the format: [threshold, TPR]\n",
    "    _1b_ans.append([thresh, fpr])\n",
    "\n",
    "# Now display the data\n",
    "cols = ['Threshold', 'FPR']\n",
    "rows = [str(i+1) for i in range(10)]\n",
    "pd.DataFrame(np.asarray(_1b_ans), index=rows, columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a40bf4",
   "metadata": {},
   "source": [
    "### 1.c: \n",
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45ef7448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "    Threshold  Accuracy\n1        0.98  1.000000\n2        0.92  1.000000\n3        0.87  0.666667\n4        0.76  0.750000\n5        0.74  0.600000\n6        0.61  0.500000\n7        0.57  0.571429\n8        0.38  0.625000\n9        0.34  0.555556\n10       0.32  0.500000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Threshold</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.98</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.92</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.87</td>\n      <td>0.666667</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.76</td>\n      <td>0.750000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.74</td>\n      <td>0.600000</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.61</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.57</td>\n      <td>0.571429</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.38</td>\n      <td>0.625000</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.34</td>\n      <td>0.555556</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.32</td>\n      <td>0.500000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note, this is essentially copied from 1a with one modified line\n",
    "# Let's get the confusion matrices of 10 thresholds using the prediction values\n",
    "# Use list comprehension to generate a list of all the pred columns for every row in the data\n",
    "THRESHOLDS = [row[YPRED_COLUMN] for row in QUESTION_1_2_DATA]\n",
    "\n",
    "# Now let's make a 2D array that we are going to print for the answer\n",
    "_1c_ans = []\n",
    "\n",
    "# Loop through all the different thresholds we want to use\n",
    "for thresh in THRESHOLDS:\n",
    "    # retrieve the confusion matrix using this threshold\n",
    "    confusion_matrix = get_confusion_matrix(QUESTION_1_2_DATA, thresh)\n",
    "\n",
    "    # ACC is (True positives) / (True positives + False positives)\n",
    "    acc = float(confusion_matrix.true_positives) / float(confusion_matrix.true_positives + confusion_matrix.false_positives)\n",
    "\n",
    "    # Add this entry to the data we want to display in the format: [threshold, TPR]\n",
    "    _1c_ans.append([thresh, acc])\n",
    "\n",
    "# Now display the data\n",
    "cols = ['Threshold', 'Accuracy']\n",
    "rows = [str(i+1) for i in range(10)]\n",
    "pd.DataFrame(np.asarray(_1c_ans), index=rows, columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de49f175",
   "metadata": {},
   "source": [
    "Threshold the classifier output, Ypred, at each possible value (use a greater than equal to\n",
    "comparison).\n",
    "Report the results as a matrix/table with rows corresponding with the 10 thresholds and\n",
    "columns reporting the different thresholds, the true positive rate (TPR), false positive rate\n",
    "(FPR), and accuracy (ACC)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf620487",
   "metadata": {},
   "source": [
    "## (Question 2)\n",
    "se the results from Question 1 to plot the ROC curve for the data. Note, plot this\n",
    "curve using the standard plotting tools rather than any special library/package available in R,\n",
    "Python, or Matlab for making ROC plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00c38498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:xlabel='tpr'>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To plot the ROC curve, we plot a TPR vs FPR graph\n",
    "# Luckily, we can actually use our answers from before to snag all of our x,y pairs that we are going to plot\n",
    "# Define a list of points to plot\n",
    "_q2_x_points = []\n",
    "_q2_y_points = []\n",
    "\n",
    "# Loop through the data from before and construct our x and y points\n",
    "for row in _1a_ans:\n",
    "    tpr = row[1]\n",
    "    _q2_x_points.append(tpr)\n",
    "\n",
    "for row in _1b_ans:\n",
    "    fpr = row[1]\n",
    "    _q2_y_points.append(fpr)\n",
    "\n",
    "# Now construct the dataframe\n",
    "df = pd.DataFrame({\n",
    "    'tpr': _q2_x_points,\n",
    "    'fpr': _q2_y_points\n",
    "})\n",
    "\n",
    "df.style.set_caption(\"ROC Curve\")\n",
    "\n",
    "# Display the xy relationship\n",
    "df.plot.line(x='tpr', y='fpr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98a6cb8",
   "metadata": {},
   "source": [
    "## (Question 3) Classificaiton of Spam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8e8f99",
   "metadata": {},
   "source": [
    "### 3.a: \n",
    "Load in the spambase data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a466d214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "      Frequency of 'make'  Frequency of 'address'  Frequency of 'all'  \\\n0                    0.00                    0.64                0.64   \n1                    0.21                    0.28                0.50   \n2                    0.06                    0.00                0.71   \n3                    0.00                    0.00                0.00   \n4                    0.00                    0.00                0.00   \n...                   ...                     ...                 ...   \n4596                 0.31                    0.00                0.62   \n4597                 0.00                    0.00                0.00   \n4598                 0.30                    0.00                0.30   \n4599                 0.96                    0.00                0.00   \n4600                 0.00                    0.00                0.65   \n\n      Frequency of '3d'  Frequency of 'our'  Frequency of 'over'  \\\n0                   0.0                0.32                 0.00   \n1                   0.0                0.14                 0.28   \n2                   0.0                1.23                 0.19   \n3                   0.0                0.63                 0.00   \n4                   0.0                0.63                 0.00   \n...                 ...                 ...                  ...   \n4596                0.0                0.00                 0.31   \n4597                0.0                0.00                 0.00   \n4598                0.0                0.00                 0.00   \n4599                0.0                0.32                 0.00   \n4600                0.0                0.00                 0.00   \n\n      Frequency of 'remove'  Frequency of 'internet'  Frequency of 'order'  \\\n0                      0.00                     0.00                  0.00   \n1                      0.21                     0.07                  0.00   \n2                      0.19                     0.12                  0.64   \n3                      0.31                     0.63                  0.31   \n4                      0.31                     0.63                  0.31   \n...                     ...                      ...                   ...   \n4596                   0.00                     0.00                  0.00   \n4597                   0.00                     0.00                  0.00   \n4598                   0.00                     0.00                  0.00   \n4599                   0.00                     0.00                  0.00   \n4600                   0.00                     0.00                  0.00   \n\n      Frequency of 'mail'  ...  Frequency of ';'  Frequency of '('  \\\n0                    0.00  ...             0.000             0.000   \n1                    0.94  ...             0.000             0.132   \n2                    0.25  ...             0.010             0.143   \n3                    0.63  ...             0.000             0.137   \n4                    0.63  ...             0.000             0.135   \n...                   ...  ...               ...               ...   \n4596                 0.00  ...             0.000             0.232   \n4597                 0.00  ...             0.000             0.000   \n4598                 0.00  ...             0.102             0.718   \n4599                 0.00  ...             0.000             0.057   \n4600                 0.00  ...             0.000             0.000   \n\n      Frequency of '['  Frequency of '!'  Frequency of '$'  Frequency of '#'  \\\n0                  0.0             0.778             0.000             0.000   \n1                  0.0             0.372             0.180             0.048   \n2                  0.0             0.276             0.184             0.010   \n3                  0.0             0.137             0.000             0.000   \n4                  0.0             0.135             0.000             0.000   \n...                ...               ...               ...               ...   \n4596               0.0             0.000             0.000             0.000   \n4597               0.0             0.353             0.000             0.000   \n4598               0.0             0.000             0.000             0.000   \n4599               0.0             0.000             0.000             0.000   \n4600               0.0             0.125             0.000             0.000   \n\n      Average Caps Running Length  Longest Caps Running Length  \\\n0                           3.756                           61   \n1                           5.114                          101   \n2                           9.821                          485   \n3                           3.537                           40   \n4                           3.537                           40   \n...                           ...                          ...   \n4596                        1.142                            3   \n4597                        1.555                            4   \n4598                        1.404                            6   \n4599                        1.147                            5   \n4600                        1.250                            5   \n\n      Total Caps Running Length  Is Spam?  \n0                           278         1  \n1                          1028         1  \n2                          2259         1  \n3                           191         1  \n4                           191         1  \n...                         ...       ...  \n4596                         88         0  \n4597                         14         0  \n4598                        118         0  \n4599                         78         0  \n4600                         40         0  \n\n[4601 rows x 58 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Frequency of 'make'</th>\n      <th>Frequency of 'address'</th>\n      <th>Frequency of 'all'</th>\n      <th>Frequency of '3d'</th>\n      <th>Frequency of 'our'</th>\n      <th>Frequency of 'over'</th>\n      <th>Frequency of 'remove'</th>\n      <th>Frequency of 'internet'</th>\n      <th>Frequency of 'order'</th>\n      <th>Frequency of 'mail'</th>\n      <th>...</th>\n      <th>Frequency of ';'</th>\n      <th>Frequency of '('</th>\n      <th>Frequency of '['</th>\n      <th>Frequency of '!'</th>\n      <th>Frequency of '$'</th>\n      <th>Frequency of '#'</th>\n      <th>Average Caps Running Length</th>\n      <th>Longest Caps Running Length</th>\n      <th>Total Caps Running Length</th>\n      <th>Is Spam?</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00</td>\n      <td>0.64</td>\n      <td>0.64</td>\n      <td>0.0</td>\n      <td>0.32</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.778</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>3.756</td>\n      <td>61</td>\n      <td>278</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.21</td>\n      <td>0.28</td>\n      <td>0.50</td>\n      <td>0.0</td>\n      <td>0.14</td>\n      <td>0.28</td>\n      <td>0.21</td>\n      <td>0.07</td>\n      <td>0.00</td>\n      <td>0.94</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0.132</td>\n      <td>0.0</td>\n      <td>0.372</td>\n      <td>0.180</td>\n      <td>0.048</td>\n      <td>5.114</td>\n      <td>101</td>\n      <td>1028</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.06</td>\n      <td>0.00</td>\n      <td>0.71</td>\n      <td>0.0</td>\n      <td>1.23</td>\n      <td>0.19</td>\n      <td>0.19</td>\n      <td>0.12</td>\n      <td>0.64</td>\n      <td>0.25</td>\n      <td>...</td>\n      <td>0.010</td>\n      <td>0.143</td>\n      <td>0.0</td>\n      <td>0.276</td>\n      <td>0.184</td>\n      <td>0.010</td>\n      <td>9.821</td>\n      <td>485</td>\n      <td>2259</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.63</td>\n      <td>0.00</td>\n      <td>0.31</td>\n      <td>0.63</td>\n      <td>0.31</td>\n      <td>0.63</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0.137</td>\n      <td>0.0</td>\n      <td>0.137</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>3.537</td>\n      <td>40</td>\n      <td>191</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.63</td>\n      <td>0.00</td>\n      <td>0.31</td>\n      <td>0.63</td>\n      <td>0.31</td>\n      <td>0.63</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0.135</td>\n      <td>0.0</td>\n      <td>0.135</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>3.537</td>\n      <td>40</td>\n      <td>191</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4596</th>\n      <td>0.31</td>\n      <td>0.00</td>\n      <td>0.62</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.31</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0.232</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>1.142</td>\n      <td>3</td>\n      <td>88</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4597</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.353</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>1.555</td>\n      <td>4</td>\n      <td>14</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4598</th>\n      <td>0.30</td>\n      <td>0.00</td>\n      <td>0.30</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.102</td>\n      <td>0.718</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>1.404</td>\n      <td>6</td>\n      <td>118</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4599</th>\n      <td>0.96</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.32</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0.057</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>1.147</td>\n      <td>5</td>\n      <td>78</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4600</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.65</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.125</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>1.250</td>\n      <td>5</td>\n      <td>40</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>4601 rows × 58 columns</p>\n</div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some constants to define for ease of access of the data,\n",
    "# Automatically generated using a python script\n",
    "WORD_FREQ_MAKE = 'word_freq_make'\n",
    "WORD_FREQ_ADDRESS = 'word_freq_address'\n",
    "WORD_FREQ_ALL = 'word_freq_all'\n",
    "WORD_FREQ_3D = 'word_freq_3d'\n",
    "WORD_FREQ_OUR = 'word_freq_our'\n",
    "WORD_FREQ_OVER = 'word_freq_over'\n",
    "WORD_FREQ_REMOVE = 'word_freq_remove'\n",
    "WORD_FREQ_INTERNET = 'word_freq_internet'\n",
    "WORD_FREQ_ORDER = 'word_freq_order'\n",
    "WORD_FREQ_MAIL = 'word_freq_mail'\n",
    "WORD_FREQ_RECEIVE = 'word_freq_receive'\n",
    "WORD_FREQ_WILL = 'word_freq_will'\n",
    "WORD_FREQ_PEOPLE = 'word_freq_people'\n",
    "WORD_FREQ_REPORT = 'word_freq_report'\n",
    "WORD_FREQ_ADDRESSES = 'word_freq_addresses'\n",
    "WORD_FREQ_FREE = 'word_freq_free'\n",
    "WORD_FREQ_BUSINESS = 'word_freq_business'\n",
    "WORD_FREQ_EMAIL = 'word_freq_email'\n",
    "WORD_FREQ_YOU = 'word_freq_you'\n",
    "WORD_FREQ_CREDIT = 'word_freq_credit'\n",
    "WORD_FREQ_YOUR = 'word_freq_your'\n",
    "WORD_FREQ_FONT = 'word_freq_font'\n",
    "WORD_FREQ_000 = 'word_freq_000'\n",
    "WORD_FREQ_MONEY = 'word_freq_money'\n",
    "WORD_FREQ_HP = 'word_freq_hp'\n",
    "WORD_FREQ_HPL = 'word_freq_hpl'\n",
    "WORD_FREQ_GEORGE = 'word_freq_george'\n",
    "WORD_FREQ_650 = 'word_freq_650'\n",
    "WORD_FREQ_LAB = 'word_freq_lab'\n",
    "WORD_FREQ_LABS = 'word_freq_labs'\n",
    "WORD_FREQ_TELNET = 'word_freq_telnet'\n",
    "WORD_FREQ_857 = 'word_freq_857'\n",
    "WORD_FREQ_DATA = 'word_freq_data'\n",
    "WORD_FREQ_415 = 'word_freq_415'\n",
    "WORD_FREQ_85 = 'word_freq_85'\n",
    "WORD_FREQ_TECHNOLOGY = 'word_freq_technology'\n",
    "WORD_FREQ_1999 = 'word_freq_1999'\n",
    "WORD_FREQ_PARTS = 'word_freq_parts'\n",
    "WORD_FREQ_PM = 'word_freq_pm'\n",
    "WORD_FREQ_DIRECT = 'word_freq_direct'\n",
    "WORD_FREQ_CS = 'word_freq_cs'\n",
    "WORD_FREQ_MEETING = 'word_freq_meeting'\n",
    "WORD_FREQ_ORIGINAL = 'word_freq_original'\n",
    "WORD_FREQ_PROJECT = 'word_freq_project'\n",
    "WORD_FREQ_RE = 'word_freq_re'\n",
    "WORD_FREQ_EDU = 'word_freq_edu'\n",
    "WORD_FREQ_TABLE = 'word_freq_table'\n",
    "WORD_FREQ_CONFERENCE = 'word_freq_conference'\n",
    "CHAR_FREQ_SEMICOLON = 'char_freq_;'\n",
    "CHAR_FREQ_L_PARENTH = 'char_freq_('\n",
    "CHAR_FREQ_L_BRACKET = 'char_freq_['\n",
    "CHAR_FREQ_EXCLAIM_POINT = 'char_freq_!'\n",
    "CHAR_FREQ_DOLLAR_SIGN = 'char_freq_$'\n",
    "CHAR_FREQ_HASHTAG = 'char_freq_#'\n",
    "CAPITAL_RUN_LENGTH_AVERAGE = 'capital_run_length_average'\n",
    "CAPITAL_RUN_LENGTH_LONGEST = 'capital_run_length_longest'\n",
    "CAPITAL_RUN_LENGTH_TOTAL = 'capital_run_length_total'\n",
    "IS_SPAM = 'is_spam'\n",
    "\n",
    "SPAMBASE_COLUMNS = [\n",
    "\tWORD_FREQ_MAKE,\n",
    "\tWORD_FREQ_ADDRESS,\n",
    "\tWORD_FREQ_ALL,\n",
    "\tWORD_FREQ_3D,\n",
    "\tWORD_FREQ_OUR,\n",
    "\tWORD_FREQ_OVER,\n",
    "\tWORD_FREQ_REMOVE,\n",
    "\tWORD_FREQ_INTERNET,\n",
    "\tWORD_FREQ_ORDER,\n",
    "\tWORD_FREQ_MAIL,\n",
    "\tWORD_FREQ_RECEIVE,\n",
    "\tWORD_FREQ_WILL,\n",
    "\tWORD_FREQ_PEOPLE,\n",
    "\tWORD_FREQ_REPORT,\n",
    "\tWORD_FREQ_ADDRESSES,\n",
    "\tWORD_FREQ_FREE,\n",
    "\tWORD_FREQ_BUSINESS,\n",
    "\tWORD_FREQ_EMAIL,\n",
    "\tWORD_FREQ_YOU,\n",
    "\tWORD_FREQ_CREDIT,\n",
    "\tWORD_FREQ_YOUR,\n",
    "\tWORD_FREQ_FONT,\n",
    "\tWORD_FREQ_000,\n",
    "\tWORD_FREQ_MONEY,\n",
    "\tWORD_FREQ_HP,\n",
    "\tWORD_FREQ_HPL,\n",
    "\tWORD_FREQ_GEORGE,\n",
    "\tWORD_FREQ_650,\n",
    "\tWORD_FREQ_LAB,\n",
    "\tWORD_FREQ_LABS,\n",
    "\tWORD_FREQ_TELNET,\n",
    "\tWORD_FREQ_857,\n",
    "\tWORD_FREQ_DATA,\n",
    "\tWORD_FREQ_415,\n",
    "\tWORD_FREQ_85,\n",
    "\tWORD_FREQ_TECHNOLOGY,\n",
    "\tWORD_FREQ_1999,\n",
    "\tWORD_FREQ_PARTS,\n",
    "\tWORD_FREQ_PM,\n",
    "\tWORD_FREQ_DIRECT,\n",
    "\tWORD_FREQ_CS,\n",
    "\tWORD_FREQ_MEETING,\n",
    "\tWORD_FREQ_ORIGINAL,\n",
    "\tWORD_FREQ_PROJECT,\n",
    "\tWORD_FREQ_RE,\n",
    "\tWORD_FREQ_EDU,\n",
    "\tWORD_FREQ_TABLE,\n",
    "\tWORD_FREQ_CONFERENCE,\n",
    "\tCHAR_FREQ_SEMICOLON,\n",
    "\tCHAR_FREQ_L_PARENTH,\n",
    "\tCHAR_FREQ_L_BRACKET,\n",
    "\tCHAR_FREQ_EXCLAIM_POINT,\n",
    "\tCHAR_FREQ_DOLLAR_SIGN,\n",
    "\tCHAR_FREQ_HASHTAG,\n",
    "\tCAPITAL_RUN_LENGTH_AVERAGE,\n",
    "\tCAPITAL_RUN_LENGTH_LONGEST,\n",
    "\tCAPITAL_RUN_LENGTH_TOTAL,\n",
    "\tIS_SPAM\n",
    "]\n",
    "SPAMBASE_CLEAN_NAMES = {\n",
    "\tWORD_FREQ_MAKE: \"Frequency of 'make'\",\n",
    "\tWORD_FREQ_ADDRESS: \"Frequency of 'address'\",\n",
    "\tWORD_FREQ_ALL: \"Frequency of 'all'\",\n",
    "\tWORD_FREQ_3D: \"Frequency of '3d'\",\n",
    "\tWORD_FREQ_OUR: \"Frequency of 'our'\",\n",
    "\tWORD_FREQ_OVER: \"Frequency of 'over'\",\n",
    "\tWORD_FREQ_REMOVE: \"Frequency of 'remove'\",\n",
    "\tWORD_FREQ_INTERNET: \"Frequency of 'internet'\",\n",
    "\tWORD_FREQ_ORDER: \"Frequency of 'order'\",\n",
    "\tWORD_FREQ_MAIL: \"Frequency of 'mail'\",\n",
    "\tWORD_FREQ_RECEIVE: \"Frequency of 'receive'\",\n",
    "\tWORD_FREQ_WILL: \"Frequency of 'will'\",\n",
    "\tWORD_FREQ_PEOPLE: \"Frequency of 'people'\",\n",
    "\tWORD_FREQ_REPORT: \"Frequency of 'report'\",\n",
    "\tWORD_FREQ_ADDRESSES: \"Frequency of 'addresses'\",\n",
    "\tWORD_FREQ_FREE: \"Frequency of 'free'\",\n",
    "\tWORD_FREQ_BUSINESS: \"Frequency of 'business'\",\n",
    "\tWORD_FREQ_EMAIL: \"Frequency of 'email'\",\n",
    "\tWORD_FREQ_YOU: \"Frequency of 'you'\",\n",
    "\tWORD_FREQ_CREDIT: \"Frequency of 'credit'\",\n",
    "\tWORD_FREQ_YOUR: \"Frequency of 'your'\",\n",
    "\tWORD_FREQ_FONT: \"Frequency of 'font'\",\n",
    "\tWORD_FREQ_000: \"Frequency of '000'\",\n",
    "\tWORD_FREQ_MONEY: \"Frequency of 'money'\",\n",
    "\tWORD_FREQ_HP: \"Frequency of 'hp'\",\n",
    "\tWORD_FREQ_HPL: \"Frequency of 'hpl'\",\n",
    "\tWORD_FREQ_GEORGE: \"Frequency of 'george'\",\n",
    "\tWORD_FREQ_650: \"Frequency of '650'\",\n",
    "\tWORD_FREQ_LAB: \"Frequency of 'lab'\",\n",
    "\tWORD_FREQ_LABS: \"Frequency of 'labs'\",\n",
    "\tWORD_FREQ_TELNET: \"Frequency of 'telnet'\",\n",
    "\tWORD_FREQ_857: \"Frequency of '857'\",\n",
    "\tWORD_FREQ_DATA: \"Frequency of 'data'\",\n",
    "\tWORD_FREQ_415: \"Frequency of '415'\",\n",
    "\tWORD_FREQ_85: \"Frequency of '85'\",\n",
    "\tWORD_FREQ_TECHNOLOGY: \"Frequency of 'technology'\",\n",
    "\tWORD_FREQ_1999: \"Frequency of '1999'\",\n",
    "\tWORD_FREQ_PARTS: \"Frequency of 'parts'\",\n",
    "\tWORD_FREQ_PM: \"Frequency of 'pm'\",\n",
    "\tWORD_FREQ_DIRECT: \"Frequency of 'direct'\",\n",
    "\tWORD_FREQ_CS: \"Frequency of 'cs'\",\n",
    "\tWORD_FREQ_MEETING: \"Frequency of 'meeting'\",\n",
    "\tWORD_FREQ_ORIGINAL: \"Frequency of 'original'\",\n",
    "\tWORD_FREQ_PROJECT: \"Frequency of 'project'\",\n",
    "\tWORD_FREQ_RE: \"Frequency of 're'\",\n",
    "\tWORD_FREQ_EDU: \"Frequency of 'edu'\",\n",
    "\tWORD_FREQ_TABLE: \"Frequency of 'table'\",\n",
    "\tWORD_FREQ_CONFERENCE: \"Frequency of 'conference'\",\n",
    "\tCHAR_FREQ_SEMICOLON: \"Frequency of ';'\",\n",
    "\tCHAR_FREQ_L_PARENTH: \"Frequency of '('\",\n",
    "\tCHAR_FREQ_L_BRACKET: \"Frequency of '['\",\n",
    "\tCHAR_FREQ_EXCLAIM_POINT: \"Frequency of '!'\",\n",
    "\tCHAR_FREQ_DOLLAR_SIGN: \"Frequency of '$'\",\n",
    "\tCHAR_FREQ_HASHTAG: \"Frequency of '#'\",\n",
    "\tCAPITAL_RUN_LENGTH_AVERAGE: \"Average Caps Running Length\",\n",
    "\tCAPITAL_RUN_LENGTH_LONGEST: \"Longest Caps Running Length\",\n",
    "\tCAPITAL_RUN_LENGTH_TOTAL: \"Total Caps Running Length\",\n",
    "\tIS_SPAM: \"Is Spam?\"\n",
    "}\n",
    "\n",
    "SPAMBASE_CLEAN_COLUMNS = [SPAMBASE_CLEAN_NAMES[var] for var in SPAMBASE_COLUMNS]\n",
    "# Just like other assignments, read the CSV\n",
    "SPAMBASE_CSV = 'spambase.data'\n",
    "SPAMBASE_DATA = pd.read_csv(SPAMBASE_CSV, names=SPAMBASE_CLEAN_COLUMNS)\n",
    "SPAMBASE_DATA.head(n=len(SPAMBASE_DATA.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6584b8",
   "metadata": {},
   "source": [
    "### 3.b: \n",
    "To see whether a classifier is actually working, we should compare it to a constant classifier\n",
    "which always predicts the same class, no matter what the input features actually are"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fca1dc",
   "metadata": {},
   "source": [
    "#### 3.b.i:\n",
    "What fraction of the e-mails are actually spam?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5bb5f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fraction of spam emails to total emails is 1813 / 4601 (39.40%)\n"
     ]
    }
   ],
   "source": [
    "# We just need spam / total data\n",
    "total_data = len(SPAMBASE_DATA.values)\n",
    "\n",
    "num_spam = 0\n",
    "# Loop through all the rows, is it spam?\n",
    "SPAMBASE_DATA.reset_index()\n",
    "for index, row in SPAMBASE_DATA.iterrows():\n",
    "\tis_spam = row[SPAMBASE_COLUMNS.index(IS_SPAM)] == 1\n",
    "\tif is_spam:\n",
    "\t\tnum_spam += 1\n",
    "\n",
    "perc = float(num_spam) / float(total_data)\n",
    "print(f\"The fraction of spam emails to total emails is {num_spam} / {total_data} ({perc*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6c8949",
   "metadata": {},
   "source": [
    "#### 3.b.ii: \n",
    "What should the constant classifier predict?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b8df0cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fff390c1",
   "metadata": {},
   "source": [
    "#### 3.b.iii: \n",
    "What is the error rate of the constant classifier? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f1fed058",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f1e5283",
   "metadata": {},
   "source": [
    "### 3.c: Model Selection and Evaluation: Three-fold Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08f4f87",
   "metadata": {},
   "source": [
    "Split the data into training, validation and test sets with 60, 20, and 20% of the data\n",
    "respectively. Make sure to split the data such that the distribution of class labels is\n",
    "approximately equal across splits - “stratify”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abb1405",
   "metadata": {},
   "source": [
    "#### 3.c.i:\n",
    "What fraction of each set: training, validation, and test sets are spam?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4ec7c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "afd62216",
   "metadata": {},
   "source": [
    "#### 3.c.ii:\n",
    "Check that two predictor variables in the data set have approximatly the same distribution in each of the sets\n",
    "Set the seed for the random generator to ”5”, Python - random state and R - set.seed(5).\n",
    "\n",
    "Helpful functions: R - sample, Matlab - cvpartition, Python - train test split from\n",
    "sklearn.model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "efe7cb36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47d6470d",
   "metadata": {},
   "source": [
    "### 3.d: Scale the predictor data to values between [0,1] using MinMax scalling.\n",
    "make sure to use training data set to set scaling parameters and apply those parameters to\n",
    "scaling the validation and testing data.\n",
    "Helpful functions: R - preProcess from caret, Python - MinMaxScaler from\n",
    "sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b51543a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac052618",
   "metadata": {},
   "source": [
    "### 3.e: KNN - K Nearest Neighbors\n",
    "For k of odd values, 5-51, fit a k-nearest-neighbor classifier to the training data. Evaluate these classifiers on the validation data. Select the best value of k (minimizes the validation error). Retrain the best model on train+validation and evaluate it on the testing data.\n",
    "\n",
    "Helpful functions: Python- KNeighborsClassifier from sklearn.neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6d2fca",
   "metadata": {},
   "source": [
    "#### 3.e.i:\n",
    "Report the training, validation and test error in a plot with x-axis as values of k and the y-axis error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17ea6cf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f6823b3",
   "metadata": {},
   "source": [
    "#### 3.e.ii:\n",
    "Report which value of k was selected as best. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46f67a83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28c29077",
   "metadata": {},
   "source": [
    "### 3.f: Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ae9f23",
   "metadata": {},
   "source": [
    "#### 3.f.i:\n",
    "Construct a classification tree to predict spam on the training data. Then print out the tree found\n",
    "Helpful functions: Python - DecisionTreeClassifier, export=graphviz from sklearn.tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e44636a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5061e279",
   "metadata": {},
   "source": [
    "#### 3.f.ii: \n",
    "Which selection criteria is used by default when learning the tree model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dfe37d1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "927064f8",
   "metadata": {},
   "source": [
    "### 3.g: Naive Bayes\n",
    "Use a Naive Bayes classifier to predict whether the emails are spam. Report the training and testing accuracy, sensitivity, specificity, and AUC. \n",
    "Helpful functions: Python - GaussianNB from sklearn.naive bayes. \n",
    "Python - sklearn.metrics library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "897361ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "480842bb",
   "metadata": {},
   "source": [
    "### 3.f: Model Selection / Evaluation: Grid Search with Cross-Validation-KFolds\n",
    "We will now incorporate cross-validation into the model selection and evaluation process\n",
    "and use it for the next two parts of the question, Q3(i) and Q3(j).\n",
    "First, split out the test set with 20% of the data. \n",
    "Helpful functions: Python - train test split from sklearn.model_selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9932b01e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a82c6139",
   "metadata": {},
   "source": [
    "### 3.i: Support Vector Machines\n",
    "Learn SVM modesl to predict spam using 10-fold cross-validation on the train+validaiton data to select the best parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e1e761",
   "metadata": {},
   "source": [
    "#### 3.i.1: \n",
    "The remaining train+validation set, from Q3(h), will be split using 10-fold cross-validation. You will do cross-validation by hand, that is with the functions:\n",
    "Helpful functions: Python - StratifiedKFold from sklearn.model selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2facaa4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "515208ca",
   "metadata": {},
   "source": [
    "#### 3.i.2: \n",
    "You should train each of the models on the training set and evaluate each model on the validation set. You will examine cost parameters of [10^−2, 10^−1, 1, 10] for both the linear and RBF kernel. \n",
    "Report out in a table/dataframe for each parameter combination (cost and kernel) the following mean performances on the validation\n",
    "set: accuracy, precision, and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a70f85f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1588e5fc",
   "metadata": {},
   "source": [
    "#### 3.i.3: \n",
    "Report the best parameter combination (cost and kernel) using accuracy\n",
    "as the criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e07f1af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "054f0f58",
   "metadata": {},
   "source": [
    "#### 3.i.4: \n",
    "Retrain a model with the best parameters on train+validation and evaluate it on the testing data. Report this model’s accuracy, precision and recall.\n",
    "Helpful Functions: Python- SVC from sklearn.svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b95da574",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c588d1fc",
   "metadata": {},
   "source": [
    "### 3.j: Ensemble Methods - Part 1\n",
    "Learn boostin gmodesl to predict spam using 10-fold cross-validation on th etrain+validaion data to select the best parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa447b67",
   "metadata": {},
   "source": [
    "#### 3.j.i: \n",
    "You will use the same method as in Q3(i)i to set up and perform the cross-validation by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a581d67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "533c7373",
   "metadata": {},
   "source": [
    "#### 3.j.ii:\n",
    "Train AdaBoost models with the number of decision stumps to be [10, 25,\n",
    "50, 100]. Report out in a table/datafram the mean F1 score for each parameter value.\n",
    "Functions: Python - AdaBoostClassifier from sklearn.ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01711f50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2be68f3",
   "metadata": {},
   "source": [
    "#### 3.j.iii\n",
    "Report out the best parameter value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fcfbac37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10e8547d",
   "metadata": {},
   "source": [
    "#### 3.j.iv:\n",
    "Retrain a model with the best parameters on train+validation and evaluate it on the testing data. Report this model’s F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89858422",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "013fdc5a",
   "metadata": {},
   "source": [
    "### 3.k:\n",
    "Model Selection and Evaluation: Grid Search with Cross-Validation-GridSearchCV\n",
    "\n",
    "We will again perform a GridSearch with cross-validation on the train+validation set, but here we will make use of the functions that do the cross-validation internally. \n",
    "\n",
    "Functions: Python - GridSearchCV from sklearn.model selection. \n",
    "\n",
    "Here again, start by splitting out the test set with 20% of the data. \n",
    "\n",
    "Helpful functions: Python -train test split from sklearn.model selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0762bc03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23082f5e",
   "metadata": {},
   "source": [
    "### 3.l: Ensemble Methods - Part 2\n",
    "Let's examine bagging ensamble approaches for predicting spam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ec078b",
   "metadata": {},
   "source": [
    "#### 3.l.i:\n",
    "The remaining train+validation set, from Q3(k), will be using 10-fold cross-validation with the GridSearchCV functions.\n",
    "Functions: Python - GridSearchCV from sklearn.model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c5c186bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01d8e9bb",
   "metadata": {},
   "source": [
    "#### 3.l.ii: \n",
    "Train Random Forest models with parameters of the maximum number of\n",
    "features [2, 4, 8, 16] and number of estimators of [25, 50, 100]. \n",
    "Report the mean AUC on validation set for the different parameter combinations.\n",
    "Functions: Python - RandomForestClassifier from sklearn.ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35569a57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a25e8bb",
   "metadata": {},
   "source": [
    "#### 3.l.iii:\n",
    "Report out the best parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db8a47c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45a67e32",
   "metadata": {},
   "source": [
    "#### 3.l.iv: \n",
    "Retrain a model with the best parameters on train+validation and evaluate it on the testing data. Resport this model's AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e14a877",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fbbffd6d",
   "metadata": {},
   "source": [
    "## (Question 4) NBA Baskeball - Using Pipelines / Workflows\n",
    "For this problem you will use a data set of 9,958 NBA basketball games (the 2016-2019 seasons).\n",
    "This dataset of the games and the associated properties has been collected from NBA website\n",
    "API - https://www.nba.com/. You will use this data set with the goal to predict whether\n",
    "a team will win a game"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92780a94",
   "metadata": {},
   "source": [
    "The data set variables consist of the following:\n",
    "- SEASON ID, GAME ID, GAME DATE - variables that are to be ignored for prediction, but here\n",
    "to recognize the individual samples\n",
    "- TEAM A, TEAM B, MATCHUP - variables describing the two teams in a game.\n",
    "- WON - This is the target / class feature to be predicted.\n",
    "The remaining variables are predictor variables for the models. They come in pairs\n",
    "“* DIFF” and “* A” reporting the given statistic as the difference between Team A and\n",
    "Team B and the statistic itself for Team A.\n",
    "- FG PCT DIFF, FG PCT A - field goal percentage.\n",
    "- FGM DIFF, FGM A - number of field goals made.\n",
    "- FG3 PCT DIFF, FG3 PCT A - percentage of 3-point shots made.\n",
    "- FG3M DIFF, FG3M A - number of 3-point shots made.\n",
    "- FT PCT DIFF, FT PCT A - percentage of free throws made.\n",
    "- FTM DIFF, FTM A - number of free throws made.\n",
    "- REB DIFF, REB A - number of rebounds.\n",
    "- AST DIFF, AST A - number of assists.\n",
    "- STL DIFF, STL A - number of steals.\n",
    "- TOV DIFF, TOV A - number of turnovers.\n",
    "- PF DIFF, PF A - number of personal fouls.\n",
    "\n",
    "For this question, you will make use of the pipeline and workflow functions to simplify the code needed to select and evaluate multiple methods.\n",
    "Functions: Python - make pipeline in sklearn.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bae8545",
   "metadata": {},
   "source": [
    "### 4.a: \n",
    "Load in the NBA data.\n",
    "There are a few missing values, remove any rows that contains missing values. How many samples remain?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d21860c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing 50 samples, 9908 remain.\n"
     ]
    },
    {
     "data": {
      "text/plain": "     Season Id     Game Id Game Date Team A Team B      Matchup Won  \\\n1        42019    41900406  10/11/20    MIA    LAL  MIA vs. LAL   0   \n2        42019    41900405   10/9/20    LAL    MIA  LAL vs. MIA   0   \n3        42019    41900404   10/6/20    MIA    LAL  MIA vs. LAL   0   \n4        42019    41900403   10/4/20    MIA    LAL  MIA vs. LAL   1   \n5        42019    41900402   10/2/20    LAL    MIA  LAL vs. MIA   1   \n...        ...         ...       ...    ...    ...          ...  ..   \n9954     12016  1011600005    5/4/16    CON    CHI  CON vs. CHI   1   \n9955     12016  1011600004    5/4/16    SAN    ATL  SAN vs. ATL   1   \n9956     12016  1011600003    5/4/16    SEA    PHO  SEA vs. PHO   0   \n9957     12016  1011600002    5/1/16    CHI    NYL  CHI vs. NYL   1   \n9958     12016  1011600001    5/1/16    IND    DAL  IND vs. DAL   1   \n\n     Field Goal % Difference A Team Field Goal % Field Goal Difference  ...  \\\n1                      -0.04               0.443                    -8  ...   \n2                      0.005               0.463                     0  ...   \n3                     -0.016               0.427                    -3  ...   \n4                      0.083               0.513                     7  ...   \n5                     -0.002               0.505                    13  ...   \n...                      ...                 ...                   ...  ...   \n9954                  -0.018                0.45                    -2  ...   \n9955                       0                 0.4                     2  ...   \n9956                  -0.097               0.338                    -5  ...   \n9957                   0.215               0.538                    14  ...   \n9958                  -0.029               0.471                     0  ...   \n\n     Rebounds Difference A Team Rebounds Assists Difference A Team Assists  \\\n1                     -5              41                  2             25   \n2                      6              41                 -5             21   \n3                     -3              39                 -7             18   \n4                     -6              37                  2             25   \n5                      7              44                  3             32   \n...                  ...             ...                ...            ...   \n9954                   4              32                 -2             16   \n9955                   1              38                 -4             13   \n9956                  -4              30                 -3             12   \n9957                  -7              29                 13             19   \n9958                   9              38                 -4             12   \n\n     Steals Difference A Team Steals Turnovers Difference A Team Turnovers  \\\n1                   -1             4                    1               13   \n2                    3            10                    2               15   \n3                    3             8                   -4               11   \n4                    0             8                   -7               12   \n5                    4             6                    0                9   \n...                ...           ...                  ...              ...   \n9954                -2             8                   -1               21   \n9955                 2             8                   -5               12   \n9956                 6            10                   -5               11   \n9957                 4             9                  -11                8   \n9958                 2            12                    1               21   \n\n     Personal Fouls Difference A Team Personal Fouls  \n1                           -4                    18  \n2                            2                    21  \n3                            7                    21  \n4                            1                    23  \n5                            3                    26  \n...                        ...                   ...  \n9954                         6                    27  \n9955                         4                    21  \n9956                         3                    28  \n9957                        -4                    19  \n9958                        -4                    27  \n\n[9908 rows x 29 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Season Id</th>\n      <th>Game Id</th>\n      <th>Game Date</th>\n      <th>Team A</th>\n      <th>Team B</th>\n      <th>Matchup</th>\n      <th>Won</th>\n      <th>Field Goal % Difference</th>\n      <th>A Team Field Goal %</th>\n      <th>Field Goal Difference</th>\n      <th>...</th>\n      <th>Rebounds Difference</th>\n      <th>A Team Rebounds</th>\n      <th>Assists Difference</th>\n      <th>A Team Assists</th>\n      <th>Steals Difference</th>\n      <th>A Team Steals</th>\n      <th>Turnovers Difference</th>\n      <th>A Team Turnovers</th>\n      <th>Personal Fouls Difference</th>\n      <th>A Team Personal Fouls</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>42019</td>\n      <td>41900406</td>\n      <td>10/11/20</td>\n      <td>MIA</td>\n      <td>LAL</td>\n      <td>MIA vs. LAL</td>\n      <td>0</td>\n      <td>-0.04</td>\n      <td>0.443</td>\n      <td>-8</td>\n      <td>...</td>\n      <td>-5</td>\n      <td>41</td>\n      <td>2</td>\n      <td>25</td>\n      <td>-1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>13</td>\n      <td>-4</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>42019</td>\n      <td>41900405</td>\n      <td>10/9/20</td>\n      <td>LAL</td>\n      <td>MIA</td>\n      <td>LAL vs. MIA</td>\n      <td>0</td>\n      <td>0.005</td>\n      <td>0.463</td>\n      <td>0</td>\n      <td>...</td>\n      <td>6</td>\n      <td>41</td>\n      <td>-5</td>\n      <td>21</td>\n      <td>3</td>\n      <td>10</td>\n      <td>2</td>\n      <td>15</td>\n      <td>2</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>42019</td>\n      <td>41900404</td>\n      <td>10/6/20</td>\n      <td>MIA</td>\n      <td>LAL</td>\n      <td>MIA vs. LAL</td>\n      <td>0</td>\n      <td>-0.016</td>\n      <td>0.427</td>\n      <td>-3</td>\n      <td>...</td>\n      <td>-3</td>\n      <td>39</td>\n      <td>-7</td>\n      <td>18</td>\n      <td>3</td>\n      <td>8</td>\n      <td>-4</td>\n      <td>11</td>\n      <td>7</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>42019</td>\n      <td>41900403</td>\n      <td>10/4/20</td>\n      <td>MIA</td>\n      <td>LAL</td>\n      <td>MIA vs. LAL</td>\n      <td>1</td>\n      <td>0.083</td>\n      <td>0.513</td>\n      <td>7</td>\n      <td>...</td>\n      <td>-6</td>\n      <td>37</td>\n      <td>2</td>\n      <td>25</td>\n      <td>0</td>\n      <td>8</td>\n      <td>-7</td>\n      <td>12</td>\n      <td>1</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>42019</td>\n      <td>41900402</td>\n      <td>10/2/20</td>\n      <td>LAL</td>\n      <td>MIA</td>\n      <td>LAL vs. MIA</td>\n      <td>1</td>\n      <td>-0.002</td>\n      <td>0.505</td>\n      <td>13</td>\n      <td>...</td>\n      <td>7</td>\n      <td>44</td>\n      <td>3</td>\n      <td>32</td>\n      <td>4</td>\n      <td>6</td>\n      <td>0</td>\n      <td>9</td>\n      <td>3</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9954</th>\n      <td>12016</td>\n      <td>1011600005</td>\n      <td>5/4/16</td>\n      <td>CON</td>\n      <td>CHI</td>\n      <td>CON vs. CHI</td>\n      <td>1</td>\n      <td>-0.018</td>\n      <td>0.45</td>\n      <td>-2</td>\n      <td>...</td>\n      <td>4</td>\n      <td>32</td>\n      <td>-2</td>\n      <td>16</td>\n      <td>-2</td>\n      <td>8</td>\n      <td>-1</td>\n      <td>21</td>\n      <td>6</td>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th>9955</th>\n      <td>12016</td>\n      <td>1011600004</td>\n      <td>5/4/16</td>\n      <td>SAN</td>\n      <td>ATL</td>\n      <td>SAN vs. ATL</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.4</td>\n      <td>2</td>\n      <td>...</td>\n      <td>1</td>\n      <td>38</td>\n      <td>-4</td>\n      <td>13</td>\n      <td>2</td>\n      <td>8</td>\n      <td>-5</td>\n      <td>12</td>\n      <td>4</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>9956</th>\n      <td>12016</td>\n      <td>1011600003</td>\n      <td>5/4/16</td>\n      <td>SEA</td>\n      <td>PHO</td>\n      <td>SEA vs. PHO</td>\n      <td>0</td>\n      <td>-0.097</td>\n      <td>0.338</td>\n      <td>-5</td>\n      <td>...</td>\n      <td>-4</td>\n      <td>30</td>\n      <td>-3</td>\n      <td>12</td>\n      <td>6</td>\n      <td>10</td>\n      <td>-5</td>\n      <td>11</td>\n      <td>3</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>9957</th>\n      <td>12016</td>\n      <td>1011600002</td>\n      <td>5/1/16</td>\n      <td>CHI</td>\n      <td>NYL</td>\n      <td>CHI vs. NYL</td>\n      <td>1</td>\n      <td>0.215</td>\n      <td>0.538</td>\n      <td>14</td>\n      <td>...</td>\n      <td>-7</td>\n      <td>29</td>\n      <td>13</td>\n      <td>19</td>\n      <td>4</td>\n      <td>9</td>\n      <td>-11</td>\n      <td>8</td>\n      <td>-4</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>9958</th>\n      <td>12016</td>\n      <td>1011600001</td>\n      <td>5/1/16</td>\n      <td>IND</td>\n      <td>DAL</td>\n      <td>IND vs. DAL</td>\n      <td>1</td>\n      <td>-0.029</td>\n      <td>0.471</td>\n      <td>0</td>\n      <td>...</td>\n      <td>9</td>\n      <td>38</td>\n      <td>-4</td>\n      <td>12</td>\n      <td>2</td>\n      <td>12</td>\n      <td>1</td>\n      <td>21</td>\n      <td>-4</td>\n      <td>27</td>\n    </tr>\n  </tbody>\n</table>\n<p>9908 rows × 29 columns</p>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEASON_ID = \"season_id\"\n",
    "GAME_ID = 'game_id'\n",
    "GAME_DATE = 'game_date'\n",
    "\n",
    "TEAM_A = 'team_a'\n",
    "TEAM_B = 'team_b'\n",
    "MATCHUP = 'matchup'\n",
    "\n",
    "WON = 'won'\n",
    "\n",
    "FIELD_GOAL_PERC_DIFF = 'field_goal_perc_diff'\n",
    "FIELD_GOAL_PERC_A = 'field_goal_perc_A'\n",
    "\n",
    "FIELD_GOAL_MADE_DIFF = 'field_goal_made_diff'\n",
    "FIELD_GOAL_MADE_A = 'field_goal_made_A'\n",
    "\n",
    "THREE_POINTERS_MADE_PERC_DIFF = 'three_pointers_made_perc_diff'\n",
    "THREE_POINTERS_MADE_PERC_A = 'three_pointers_made_perc_A'\n",
    "\n",
    "THREE_POINTERS_MADE_DIFF = 'three_pointers_made_diff'\n",
    "THREE_POINTERS_MADE_A = 'three_pointers_made_A'\n",
    "\n",
    "FREE_THROWS_MADE_PERC_DIFF = 'free_throws_made_perc_diff'\n",
    "FREE_THROWS_MADE_PERC_A = 'free_throws_made_perc_A'\n",
    "\n",
    "FREE_THROWS_MADE_DIFF = 'free_throws_made_diff'\n",
    "FREE_THROWS_MADE_A = 'free_throws_made_A'\n",
    "\n",
    "REBOUNDS_DIFF = 'rebounds_diff'\n",
    "REBOUNDS_A = 'rebounds_A'\n",
    "\n",
    "ASSISTS_DIFF = 'assists_diff'\n",
    "ASSISTS_A = 'assists_A'\n",
    "\n",
    "STEALS_DIFF = 'steals_diff'\n",
    "STEALS_A = 'steals_A'\n",
    "\n",
    "TURNOVERS_DIFF = 'turnovers_diff'\n",
    "TURNOVERS_A = 'turnovers_A'\n",
    "\n",
    "PERSONAL_FOULS_DIFF = 'personal_fouls_diff'\n",
    "PERSONAL_FOULS_A = 'personal_fouls_A'\n",
    "\n",
    "# The following two data structures were generated automatically by a python script\n",
    "NBA_COLUMNS = [\n",
    "\tSEASON_ID,\n",
    "\tGAME_ID,\n",
    "\tGAME_DATE,\n",
    "\tTEAM_A,\n",
    "\tTEAM_B,\n",
    "\tMATCHUP,\n",
    "\tWON,\n",
    "\tFIELD_GOAL_PERC_DIFF,\n",
    "\tFIELD_GOAL_PERC_A,\n",
    "\tFIELD_GOAL_MADE_DIFF,\n",
    "\tFIELD_GOAL_MADE_A,\n",
    "\tTHREE_POINTERS_MADE_PERC_DIFF,\n",
    "\tTHREE_POINTERS_MADE_PERC_A,\n",
    "\tTHREE_POINTERS_MADE_DIFF,\n",
    "\tTHREE_POINTERS_MADE_A,\n",
    "\tFREE_THROWS_MADE_PERC_DIFF,\n",
    "\tFREE_THROWS_MADE_PERC_A,\n",
    "\tFREE_THROWS_MADE_DIFF,\n",
    "\tFREE_THROWS_MADE_A,\n",
    "\tREBOUNDS_DIFF,\n",
    "\tREBOUNDS_A,\n",
    "\tASSISTS_DIFF,\n",
    "\tASSISTS_A,\n",
    "\tSTEALS_DIFF,\n",
    "\tSTEALS_A,\n",
    "\tTURNOVERS_DIFF,\n",
    "\tTURNOVERS_A,\n",
    "\tPERSONAL_FOULS_DIFF,\n",
    "\tPERSONAL_FOULS_A,\n",
    "]\n",
    "\n",
    "NBA_CLEAN_NAMES = {\n",
    "\tSEASON_ID: \"Season Id\",\n",
    "\tGAME_ID: \"Game Id\",\n",
    "\tGAME_DATE: \"Game Date\",\n",
    "\tTEAM_A: \"Team A\",\n",
    "\tTEAM_B: \"Team B\",\n",
    "\tMATCHUP: \"Matchup\",\n",
    "\tWON: \"Won\",\n",
    "\tFIELD_GOAL_PERC_DIFF: \"Field Goal % Difference\",\n",
    "\tFIELD_GOAL_PERC_A: \"A Team Field Goal %\",\n",
    "\tFIELD_GOAL_MADE_DIFF: \"Field Goal Difference\",\n",
    "\tFIELD_GOAL_MADE_A: \"A Team Field Goal\",\n",
    "\tTHREE_POINTERS_MADE_PERC_DIFF: \"Three Pointers % Difference\",\n",
    "\tTHREE_POINTERS_MADE_PERC_A: \"A Team Three Pointers %\",\n",
    "\tTHREE_POINTERS_MADE_DIFF: \"Three Pointers Difference\",\n",
    "\tTHREE_POINTERS_MADE_A: \"A Team Three Pointers\",\n",
    "\tFREE_THROWS_MADE_PERC_DIFF: \"Free Throws % Difference\",\n",
    "\tFREE_THROWS_MADE_PERC_A: \"A Team Free Throws %\",\n",
    "\tFREE_THROWS_MADE_DIFF: \"Free Throws Difference\",\n",
    "\tFREE_THROWS_MADE_A: \"A Team Free Throws\",\n",
    "\tREBOUNDS_DIFF: \"Rebounds Difference\",\n",
    "\tREBOUNDS_A: \"A Team Rebounds\",\n",
    "\tASSISTS_DIFF: \"Assists Difference\",\n",
    "\tASSISTS_A: \"A Team Assists\",\n",
    "\tSTEALS_DIFF: \"Steals Difference\",\n",
    "\tSTEALS_A: \"A Team Steals\",\n",
    "\tTURNOVERS_DIFF: \"Turnovers Difference\",\n",
    "\tTURNOVERS_A: \"A Team Turnovers\",\n",
    "\tPERSONAL_FOULS_DIFF: \"Personal Fouls Difference\",\n",
    "\tPERSONAL_FOULS_A: \"A Team Personal Fouls\",\n",
    "}\n",
    "\n",
    "NBA_CLEAN_COLUMNS = [NBA_CLEAN_NAMES[var] for var in NBA_COLUMNS]\n",
    "\n",
    "\n",
    "NBA_CSV = 'nba.csv'\n",
    "NBA_DATA = pd.read_csv(NBA_CSV, names=NBA_CLEAN_COLUMNS)\n",
    "# First row is just col titles, garbage in our case\n",
    "NBA_DATA = NBA_DATA[1:]\n",
    "\n",
    "# How many samples do we have?\n",
    "num_samples = len(NBA_DATA.values)\n",
    "\n",
    "# Purge samples containing null values\n",
    "\n",
    "# Make a set of rows to delete\n",
    "ROWS_MARKED_FOR_DELETION = set()\n",
    "\n",
    "samples_removed = 0\n",
    "\n",
    "# Find indeces that should be removed, loop through all the rows in the table\n",
    "NBA_DATA.reset_index()\n",
    "for i, match in NBA_DATA.iterrows():\n",
    "    if any(match.isnull()):\n",
    "        ROWS_MARKED_FOR_DELETION.add(i)\n",
    "\n",
    "for ind in sorted(ROWS_MARKED_FOR_DELETION, reverse=True):\n",
    "    NBA_DATA = NBA_DATA.drop(index=ind)\n",
    "    samples_removed += 1\n",
    "\n",
    "samples_remaining = len(NBA_DATA.values)\n",
    "\n",
    "print(f\"After removing {samples_removed} samples, {samples_remaining} remain.\")\n",
    "\n",
    "NBA_DATA.reset_index()\n",
    "NBA_DATA.head(n=len(NBA_DATA.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e723e7",
   "metadata": {},
   "source": [
    "### 4.b: \n",
    "You will not use the following columns for your predictors: SEASON ID, GAME ID, GAME DATE, TEAM A, TEAM B, MATCHUP. \n",
    "The WON column will become what you are trying to predict and the remaining columns your input variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "22f96585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "     Won Field Goal % Difference A Team Field Goal % Field Goal Difference  \\\n1      0                   -0.04               0.443                    -8   \n2      0                   0.005               0.463                     0   \n3      0                  -0.016               0.427                    -3   \n4      1                   0.083               0.513                     7   \n5      1                  -0.002               0.505                    13   \n...   ..                     ...                 ...                   ...   \n9954   1                  -0.018                0.45                    -2   \n9955   1                       0                 0.4                     2   \n9956   0                  -0.097               0.338                    -5   \n9957   1                   0.215               0.538                    14   \n9958   1                  -0.029               0.471                     0   \n\n     A Team Field Goal Three Pointers % Difference A Team Three Pointers %  \\\n1                   35                       0.043                   0.357   \n2                   38                      -0.056                   0.368   \n3                   32                      -0.015                   0.344   \n4                   41                        0.02                   0.353   \n5                   49                      -0.067                    0.34   \n...                ...                         ...                     ...   \n9954                27                       0.013                   0.346   \n9955                28                       0.125                   0.375   \n9956                22                      -0.039                   0.294   \n9957                35                       0.288                   0.538   \n9958                33                      -0.062                   0.409   \n\n     Three Pointers Difference A Team Three Pointers Free Throws % Difference  \\\n1                           -1                    10                   -0.052   \n2                            0                    14                   -0.098   \n3                           -3                    11                   -0.049   \n4                           -2                    12                    0.154   \n5                            5                    16                   -0.324   \n...                        ...                   ...                      ...   \n9954                         7                     9                    -0.03   \n9955                         0                     3                    0.127   \n9956                         1                     5                   -0.214   \n9957                         2                     7                   -0.104   \n9958                         1                     9                    0.294   \n\n      ... Rebounds Difference A Team Rebounds Assists Difference  \\\n1     ...                  -5              41                  2   \n2     ...                   6              41                 -5   \n3     ...                  -3              39                 -7   \n4     ...                  -6              37                  2   \n5     ...                   7              44                  3   \n...   ...                 ...             ...                ...   \n9954  ...                   4              32                 -2   \n9955  ...                   1              38                 -4   \n9956  ...                  -4              30                 -3   \n9957  ...                  -7              29                 13   \n9958  ...                   9              38                 -4   \n\n     A Team Assists Steals Difference A Team Steals Turnovers Difference  \\\n1                25                -1             4                    1   \n2                21                 3            10                    2   \n3                18                 3             8                   -4   \n4                25                 0             8                   -7   \n5                32                 4             6                    0   \n...             ...               ...           ...                  ...   \n9954             16                -2             8                   -1   \n9955             13                 2             8                   -5   \n9956             12                 6            10                   -5   \n9957             19                 4             9                  -11   \n9958             12                 2            12                    1   \n\n     A Team Turnovers Personal Fouls Difference A Team Personal Fouls  \n1                  13                        -4                    18  \n2                  15                         2                    21  \n3                  11                         7                    21  \n4                  12                         1                    23  \n5                   9                         3                    26  \n...               ...                       ...                   ...  \n9954               21                         6                    27  \n9955               12                         4                    21  \n9956               11                         3                    28  \n9957                8                        -4                    19  \n9958               21                        -4                    27  \n\n[9908 rows x 23 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Won</th>\n      <th>Field Goal % Difference</th>\n      <th>A Team Field Goal %</th>\n      <th>Field Goal Difference</th>\n      <th>A Team Field Goal</th>\n      <th>Three Pointers % Difference</th>\n      <th>A Team Three Pointers %</th>\n      <th>Three Pointers Difference</th>\n      <th>A Team Three Pointers</th>\n      <th>Free Throws % Difference</th>\n      <th>...</th>\n      <th>Rebounds Difference</th>\n      <th>A Team Rebounds</th>\n      <th>Assists Difference</th>\n      <th>A Team Assists</th>\n      <th>Steals Difference</th>\n      <th>A Team Steals</th>\n      <th>Turnovers Difference</th>\n      <th>A Team Turnovers</th>\n      <th>Personal Fouls Difference</th>\n      <th>A Team Personal Fouls</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>-0.04</td>\n      <td>0.443</td>\n      <td>-8</td>\n      <td>35</td>\n      <td>0.043</td>\n      <td>0.357</td>\n      <td>-1</td>\n      <td>10</td>\n      <td>-0.052</td>\n      <td>...</td>\n      <td>-5</td>\n      <td>41</td>\n      <td>2</td>\n      <td>25</td>\n      <td>-1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>13</td>\n      <td>-4</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0.005</td>\n      <td>0.463</td>\n      <td>0</td>\n      <td>38</td>\n      <td>-0.056</td>\n      <td>0.368</td>\n      <td>0</td>\n      <td>14</td>\n      <td>-0.098</td>\n      <td>...</td>\n      <td>6</td>\n      <td>41</td>\n      <td>-5</td>\n      <td>21</td>\n      <td>3</td>\n      <td>10</td>\n      <td>2</td>\n      <td>15</td>\n      <td>2</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>-0.016</td>\n      <td>0.427</td>\n      <td>-3</td>\n      <td>32</td>\n      <td>-0.015</td>\n      <td>0.344</td>\n      <td>-3</td>\n      <td>11</td>\n      <td>-0.049</td>\n      <td>...</td>\n      <td>-3</td>\n      <td>39</td>\n      <td>-7</td>\n      <td>18</td>\n      <td>3</td>\n      <td>8</td>\n      <td>-4</td>\n      <td>11</td>\n      <td>7</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>0.083</td>\n      <td>0.513</td>\n      <td>7</td>\n      <td>41</td>\n      <td>0.02</td>\n      <td>0.353</td>\n      <td>-2</td>\n      <td>12</td>\n      <td>0.154</td>\n      <td>...</td>\n      <td>-6</td>\n      <td>37</td>\n      <td>2</td>\n      <td>25</td>\n      <td>0</td>\n      <td>8</td>\n      <td>-7</td>\n      <td>12</td>\n      <td>1</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1</td>\n      <td>-0.002</td>\n      <td>0.505</td>\n      <td>13</td>\n      <td>49</td>\n      <td>-0.067</td>\n      <td>0.34</td>\n      <td>5</td>\n      <td>16</td>\n      <td>-0.324</td>\n      <td>...</td>\n      <td>7</td>\n      <td>44</td>\n      <td>3</td>\n      <td>32</td>\n      <td>4</td>\n      <td>6</td>\n      <td>0</td>\n      <td>9</td>\n      <td>3</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9954</th>\n      <td>1</td>\n      <td>-0.018</td>\n      <td>0.45</td>\n      <td>-2</td>\n      <td>27</td>\n      <td>0.013</td>\n      <td>0.346</td>\n      <td>7</td>\n      <td>9</td>\n      <td>-0.03</td>\n      <td>...</td>\n      <td>4</td>\n      <td>32</td>\n      <td>-2</td>\n      <td>16</td>\n      <td>-2</td>\n      <td>8</td>\n      <td>-1</td>\n      <td>21</td>\n      <td>6</td>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th>9955</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0.4</td>\n      <td>2</td>\n      <td>28</td>\n      <td>0.125</td>\n      <td>0.375</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0.127</td>\n      <td>...</td>\n      <td>1</td>\n      <td>38</td>\n      <td>-4</td>\n      <td>13</td>\n      <td>2</td>\n      <td>8</td>\n      <td>-5</td>\n      <td>12</td>\n      <td>4</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>9956</th>\n      <td>0</td>\n      <td>-0.097</td>\n      <td>0.338</td>\n      <td>-5</td>\n      <td>22</td>\n      <td>-0.039</td>\n      <td>0.294</td>\n      <td>1</td>\n      <td>5</td>\n      <td>-0.214</td>\n      <td>...</td>\n      <td>-4</td>\n      <td>30</td>\n      <td>-3</td>\n      <td>12</td>\n      <td>6</td>\n      <td>10</td>\n      <td>-5</td>\n      <td>11</td>\n      <td>3</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>9957</th>\n      <td>1</td>\n      <td>0.215</td>\n      <td>0.538</td>\n      <td>14</td>\n      <td>35</td>\n      <td>0.288</td>\n      <td>0.538</td>\n      <td>2</td>\n      <td>7</td>\n      <td>-0.104</td>\n      <td>...</td>\n      <td>-7</td>\n      <td>29</td>\n      <td>13</td>\n      <td>19</td>\n      <td>4</td>\n      <td>9</td>\n      <td>-11</td>\n      <td>8</td>\n      <td>-4</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>9958</th>\n      <td>1</td>\n      <td>-0.029</td>\n      <td>0.471</td>\n      <td>0</td>\n      <td>33</td>\n      <td>-0.062</td>\n      <td>0.409</td>\n      <td>1</td>\n      <td>9</td>\n      <td>0.294</td>\n      <td>...</td>\n      <td>9</td>\n      <td>38</td>\n      <td>-4</td>\n      <td>12</td>\n      <td>2</td>\n      <td>12</td>\n      <td>1</td>\n      <td>21</td>\n      <td>-4</td>\n      <td>27</td>\n    </tr>\n  </tbody>\n</table>\n<p>9908 rows × 23 columns</p>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SIMPLE_NBA_DATA = NBA_DATA.copy()\n",
    "\n",
    "# Remove columns we don't need\n",
    "cols_to_remove = [\n",
    "\tNBA_CLEAN_NAMES[SEASON_ID],\n",
    "\tNBA_CLEAN_NAMES[GAME_ID],\n",
    "\tNBA_CLEAN_NAMES[GAME_DATE],\n",
    "\tNBA_CLEAN_NAMES[TEAM_A],\n",
    "\tNBA_CLEAN_NAMES[TEAM_B],\n",
    "\tNBA_CLEAN_NAMES[MATCHUP]\n",
    "]\n",
    "\n",
    "# Drop the columns\n",
    "SIMPLE_NBA_DATA = SIMPLE_NBA_DATA.drop(columns=cols_to_remove)\n",
    "SIMPLE_NBA_DATA.head(n=len(SIMPLE_NBA_DATA.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e232da4e",
   "metadata": {},
   "source": [
    "### 4.c: \n",
    "Split off a random 20% of the data for testing. Set the seed for the random generator to ”5”.\n",
    "Python - random state and R - set.seed(5).\n",
    "Helpful Python - train test split from sklearn.model selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "12b04a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "     Won Field Goal % Difference A Team Field Goal % Field Goal Difference  \\\n7632   0                  -0.033                0.34                    -7   \n5804   0                  -0.049               0.414                     4   \n9077   1                   0.152               0.543                    17   \n6881   1                   0.083               0.494                     5   \n5691   0                  -0.033               0.467                    -5   \n...   ..                     ...                 ...                   ...   \n7337   1                   0.128               0.466                     2   \n3087   0                  -0.029               0.484                     5   \n4120   0                  -0.106               0.388                   -11   \n2265   1                  -0.029               0.431                    -1   \n2956   1                   0.128               0.547                    11   \n\n     A Team Field Goal Three Pointers % Difference A Team Three Pointers %  \\\n7632                18                      -0.194                     0.1   \n5804                41                      -0.175                   0.185   \n9077                51                       0.167                   0.417   \n6881                42                       0.201                   0.423   \n5691                42                       0.011                   0.368   \n...                ...                         ...                     ...   \n7337                27                       0.098                   0.357   \n3087                46                      -0.068                   0.344   \n4120                33                      -0.014                   0.244   \n2265                28                       0.144                   0.438   \n2956                47                       0.091                   0.381   \n\n     Three Pointers Difference A Team Three Pointers Free Throws % Difference  \\\n7632                        -4                     1                   -0.183   \n5804                        -4                     5                    0.109   \n9077                        10                    15                   -0.005   \n6881                         5                    11                   -0.053   \n5691                         4                    14                    0.253   \n...                        ...                   ...                      ...   \n7337                        -2                     5                   -0.014   \n3087                        -3                    11                   -0.154   \n4120                         2                    10                   -0.015   \n2265                         2                     7                    0.292   \n2956                        -1                     8                   -0.066   \n\n      ... Rebounds Difference A Team Rebounds Assists Difference  \\\n7632  ...                  -3              35                 -7   \n5804  ...                  -9              43                  8   \n9077  ...                  13              52                 21   \n6881  ...                  14              52                  9   \n5691  ...                  -2              45                 -7   \n...   ...                 ...             ...                ...   \n7337  ...                  -1              34                  3   \n3087  ...                   0              40                  2   \n4120  ...                 -13              38                 -3   \n2265  ...                   9              33                 -2   \n2956  ...                   4              41                 15   \n\n     A Team Assists Steals Difference A Team Steals Turnovers Difference  \\\n7632             10                -5             7                    8   \n5804             28                 5            11                   -7   \n9077             35                 7            20                   -7   \n6881             22                -3             5                    7   \n5691             19                -6             7                    9   \n...             ...               ...           ...                  ...   \n7337             17                 0             5                    3   \n3087             26                -1             4                   -3   \n4120             19                 7            12                   -3   \n2265             18                -2             5                    2   \n2956             37                 6            15                   -5   \n\n     A Team Turnovers Personal Fouls Difference A Team Personal Fouls  \n7632               23                        -5                    28  \n5804                8                         7                    20  \n9077               20                         0                    22  \n6881               17                        -3                    18  \n5691               20                         1                    18  \n...               ...                       ...                   ...  \n7337               12                         7                    22  \n3087                8                         8                    28  \n4120               17                         0                    21  \n2265               13                         0                    15  \n2956               19                         2                    23  \n\n[7926 rows x 23 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Won</th>\n      <th>Field Goal % Difference</th>\n      <th>A Team Field Goal %</th>\n      <th>Field Goal Difference</th>\n      <th>A Team Field Goal</th>\n      <th>Three Pointers % Difference</th>\n      <th>A Team Three Pointers %</th>\n      <th>Three Pointers Difference</th>\n      <th>A Team Three Pointers</th>\n      <th>Free Throws % Difference</th>\n      <th>...</th>\n      <th>Rebounds Difference</th>\n      <th>A Team Rebounds</th>\n      <th>Assists Difference</th>\n      <th>A Team Assists</th>\n      <th>Steals Difference</th>\n      <th>A Team Steals</th>\n      <th>Turnovers Difference</th>\n      <th>A Team Turnovers</th>\n      <th>Personal Fouls Difference</th>\n      <th>A Team Personal Fouls</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7632</th>\n      <td>0</td>\n      <td>-0.033</td>\n      <td>0.34</td>\n      <td>-7</td>\n      <td>18</td>\n      <td>-0.194</td>\n      <td>0.1</td>\n      <td>-4</td>\n      <td>1</td>\n      <td>-0.183</td>\n      <td>...</td>\n      <td>-3</td>\n      <td>35</td>\n      <td>-7</td>\n      <td>10</td>\n      <td>-5</td>\n      <td>7</td>\n      <td>8</td>\n      <td>23</td>\n      <td>-5</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>5804</th>\n      <td>0</td>\n      <td>-0.049</td>\n      <td>0.414</td>\n      <td>4</td>\n      <td>41</td>\n      <td>-0.175</td>\n      <td>0.185</td>\n      <td>-4</td>\n      <td>5</td>\n      <td>0.109</td>\n      <td>...</td>\n      <td>-9</td>\n      <td>43</td>\n      <td>8</td>\n      <td>28</td>\n      <td>5</td>\n      <td>11</td>\n      <td>-7</td>\n      <td>8</td>\n      <td>7</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>9077</th>\n      <td>1</td>\n      <td>0.152</td>\n      <td>0.543</td>\n      <td>17</td>\n      <td>51</td>\n      <td>0.167</td>\n      <td>0.417</td>\n      <td>10</td>\n      <td>15</td>\n      <td>-0.005</td>\n      <td>...</td>\n      <td>13</td>\n      <td>52</td>\n      <td>21</td>\n      <td>35</td>\n      <td>7</td>\n      <td>20</td>\n      <td>-7</td>\n      <td>20</td>\n      <td>0</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>6881</th>\n      <td>1</td>\n      <td>0.083</td>\n      <td>0.494</td>\n      <td>5</td>\n      <td>42</td>\n      <td>0.201</td>\n      <td>0.423</td>\n      <td>5</td>\n      <td>11</td>\n      <td>-0.053</td>\n      <td>...</td>\n      <td>14</td>\n      <td>52</td>\n      <td>9</td>\n      <td>22</td>\n      <td>-3</td>\n      <td>5</td>\n      <td>7</td>\n      <td>17</td>\n      <td>-3</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>5691</th>\n      <td>0</td>\n      <td>-0.033</td>\n      <td>0.467</td>\n      <td>-5</td>\n      <td>42</td>\n      <td>0.011</td>\n      <td>0.368</td>\n      <td>4</td>\n      <td>14</td>\n      <td>0.253</td>\n      <td>...</td>\n      <td>-2</td>\n      <td>45</td>\n      <td>-7</td>\n      <td>19</td>\n      <td>-6</td>\n      <td>7</td>\n      <td>9</td>\n      <td>20</td>\n      <td>1</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7337</th>\n      <td>1</td>\n      <td>0.128</td>\n      <td>0.466</td>\n      <td>2</td>\n      <td>27</td>\n      <td>0.098</td>\n      <td>0.357</td>\n      <td>-2</td>\n      <td>5</td>\n      <td>-0.014</td>\n      <td>...</td>\n      <td>-1</td>\n      <td>34</td>\n      <td>3</td>\n      <td>17</td>\n      <td>0</td>\n      <td>5</td>\n      <td>3</td>\n      <td>12</td>\n      <td>7</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>3087</th>\n      <td>0</td>\n      <td>-0.029</td>\n      <td>0.484</td>\n      <td>5</td>\n      <td>46</td>\n      <td>-0.068</td>\n      <td>0.344</td>\n      <td>-3</td>\n      <td>11</td>\n      <td>-0.154</td>\n      <td>...</td>\n      <td>0</td>\n      <td>40</td>\n      <td>2</td>\n      <td>26</td>\n      <td>-1</td>\n      <td>4</td>\n      <td>-3</td>\n      <td>8</td>\n      <td>8</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>4120</th>\n      <td>0</td>\n      <td>-0.106</td>\n      <td>0.388</td>\n      <td>-11</td>\n      <td>33</td>\n      <td>-0.014</td>\n      <td>0.244</td>\n      <td>2</td>\n      <td>10</td>\n      <td>-0.015</td>\n      <td>...</td>\n      <td>-13</td>\n      <td>38</td>\n      <td>-3</td>\n      <td>19</td>\n      <td>7</td>\n      <td>12</td>\n      <td>-3</td>\n      <td>17</td>\n      <td>0</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>2265</th>\n      <td>1</td>\n      <td>-0.029</td>\n      <td>0.431</td>\n      <td>-1</td>\n      <td>28</td>\n      <td>0.144</td>\n      <td>0.438</td>\n      <td>2</td>\n      <td>7</td>\n      <td>0.292</td>\n      <td>...</td>\n      <td>9</td>\n      <td>33</td>\n      <td>-2</td>\n      <td>18</td>\n      <td>-2</td>\n      <td>5</td>\n      <td>2</td>\n      <td>13</td>\n      <td>0</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>2956</th>\n      <td>1</td>\n      <td>0.128</td>\n      <td>0.547</td>\n      <td>11</td>\n      <td>47</td>\n      <td>0.091</td>\n      <td>0.381</td>\n      <td>-1</td>\n      <td>8</td>\n      <td>-0.066</td>\n      <td>...</td>\n      <td>4</td>\n      <td>41</td>\n      <td>15</td>\n      <td>37</td>\n      <td>6</td>\n      <td>15</td>\n      <td>-5</td>\n      <td>19</td>\n      <td>2</td>\n      <td>23</td>\n    </tr>\n  </tbody>\n</table>\n<p>7926 rows × 23 columns</p>\n</div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some constants that affect how our train test split functions\n",
    "PERCENT_DATA_WANTED = 0.20\n",
    "SEED = 5\n",
    "\n",
    "# Split off 20% of the data\n",
    "nba_train_data, nba_test_data = train_test_split(SIMPLE_NBA_DATA, test_size=PERCENT_DATA_WANTED, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dde5deb",
   "metadata": {},
   "source": [
    "### 4.d: \n",
    "Parameter Selection\n",
    "\n",
    "You will set up the pipeline/workflow to consider using both MinMax and Standard scaling\n",
    "approaches.\n",
    "You will consider the following four classification methods with the hyper-parameters\n",
    "specified:\n",
    "- KNN with number of neighbors = [3, 7, 11, 15, 19, 23]\n",
    "- DT with a maximum depth of the tree as [3, 5, 10]\n",
    "- SVM with a polynomial kernel with degree = [1, 2, 3, 4] and a RBF kernel and a cost parameter of [0.01, 0.1, 1]\n",
    "- RF with maximum number of features [2, 4, 8] and number of estimators of [25, 50, 100].\n",
    "When selecting the best parameters with the train+validation data use 5-fold cross-validation and use F1 measure to select the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6cff1b55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9dc40d5f",
   "metadata": {},
   "source": [
    "### 4.e: \n",
    "Report Results\n",
    "\n",
    "Once the best parameters for each model are found, retrain a model with those parameters and evaluate the performance on the test set.\n",
    "Report in a table the following information for each model: the model type (KNN, DT, SVM, RF), the best parameters selected, \n",
    "Accuracy, Precision, Recall, F1, AUC on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5d0d28f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}