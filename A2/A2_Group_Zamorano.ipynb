{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d1d2c09",
   "metadata": {},
   "source": [
    "## Assignment - A2.part2\n",
    "### Devin Hall, Tyler Birnie\n",
    "### Due: 3-2-22 @ 11:59pm\n",
    "Some pre-requisites we will need for this project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a7dae07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import math as m\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1d9372b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Here we define the data set used for questions 1 and 2 as a 2D matrix, with each row being sample #, Ytrue, Ypred\n",
    "QUESTION_1_2_DATA = (\n",
    "    [1, True, 0.98],\n",
    "    [2, True, 0.92],\n",
    "    [3, False, 0.87],\n",
    "    [4, True, 0.76],\n",
    "    [5, False, 0.74],\n",
    "    [6, False, 0.61],\n",
    "    [7, True, 0.57],\n",
    "    [8, True, 0.38],\n",
    "    [9, False, 0.34],\n",
    "    [10, False, 0.32],\n",
    ")\n",
    "\n",
    "# Some enums to make array indexing more readable\n",
    "SAMPLE_COLUMN = 0\n",
    "YTRUE_COLUMN = 1\n",
    "YPRED_COLUMN = 2\n",
    "\n",
    "# A helper class to reduce chance of human error when dealing with confusion matrix data set\n",
    "class ConfusionMatrixResult:\n",
    "    def __init__(self, tp, fp, tn, fn):\n",
    "        self.true_positives = tp\n",
    "        self.false_positives = fp\n",
    "        self.true_negatives = tn\n",
    "        self.false_negatives = fn\n",
    "\n",
    "\n",
    "# A helper function to take in a 2D array structured like above, and return # of true positives, false positives, true negatives, false negatives at a certain threshold\n",
    "# contained as a ConfusionMatrixResult\n",
    "def get_confusion_matrix(data, threshold) -> ConfusionMatrixResult:\n",
    "\n",
    "    # setup the counts of the confusion matrix\n",
    "    true_pos = 0\n",
    "    false_pos = 0\n",
    "    true_neg = 0\n",
    "    false_neg = 0\n",
    "\n",
    "    # Loop through all the data\n",
    "    for row in data:\n",
    "        # Extract the data\n",
    "        sample_num: int = row[SAMPLE_COLUMN]\n",
    "        actual_state: bool = row[YTRUE_COLUMN]\n",
    "        predicted_state: float = row[YPRED_COLUMN]\n",
    "\n",
    "        # Does this data fit in the threshold? i.e. is the predicted state >= threshold we defined\n",
    "        in_threshold = predicted_state >= threshold\n",
    "\n",
    "        # First consider the samples that are actually positive, (actual_state == True)\n",
    "        if actual_state:\n",
    "\n",
    "            # Is this in the threshold? i.e., did we make a correct prediction?\n",
    "            if in_threshold:\n",
    "                true_pos += 1  # This is a true positive\n",
    "            else:\n",
    "                false_neg += 1  # Our prediction was wrong, this will be marked as a false negative\n",
    "\n",
    "        else:\n",
    "            # Consider samples that are not positive, (actual_state == False)\n",
    "            # If it isn't in the threshold, that means we guessed correctly that it is negative\n",
    "            if not in_threshold:\n",
    "                true_neg += 1  # This is a true negative\n",
    "            else:\n",
    "                false_pos += 1  # Our prediction was wrong, we thought this was going to be positive but it wasn't\n",
    "\n",
    "    # Now that we looped through all the data, let's return the confusion matrix\n",
    "    return ConfusionMatrixResult(tp=true_pos, fp=false_pos, tn=true_neg, fn=false_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b7a1e7",
   "metadata": {},
   "source": [
    "## (Question 1) For the following data set, compute the:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d6581d",
   "metadata": {},
   "source": [
    "### 1.a: \n",
    "True positive rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f862f5dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>TPR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.38</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.34</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.32</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Threshold  TPR\n",
       "1        0.98  0.2\n",
       "2        0.92  0.4\n",
       "3        0.87  0.4\n",
       "4        0.76  0.6\n",
       "5        0.74  0.6\n",
       "6        0.61  0.6\n",
       "7        0.57  0.8\n",
       "8        0.38  1.0\n",
       "9        0.34  1.0\n",
       "10       0.32  1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's get the confusion matrices of 10 thresholds using the prediction values\n",
    "# Use list comprehension to generate a list of all the pred columns for every row in the data\n",
    "THRESHOLDS = [row[YPRED_COLUMN] for row in QUESTION_1_2_DATA]\n",
    "\n",
    "# Now let's make a 2D array that we are going to print for the answer\n",
    "_1a_ans = []\n",
    "\n",
    "# Loop through all the different thresholds we want to use\n",
    "for thresh in THRESHOLDS:\n",
    "    # retrieve the confusion matrix using this threshold\n",
    "    confusion_matrix = get_confusion_matrix(QUESTION_1_2_DATA, thresh)\n",
    "\n",
    "    # TPR is true positives / (true positives + false negatives)\n",
    "    tpr = float(confusion_matrix.true_positives) / float(confusion_matrix.true_positives + confusion_matrix.false_negatives)\n",
    "\n",
    "    # Add this entry to the data we want to display in the format: [threshold, TPR]\n",
    "    _1a_ans.append([thresh, tpr])\n",
    "\n",
    "# Now display the data\n",
    "cols = ['Threshold', 'TPR']\n",
    "rows = [str(i+1) for i in range(10)]\n",
    "pd.DataFrame(np.asarray(_1a_ans), index=rows, columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2022299",
   "metadata": {},
   "source": [
    "### 1.b: \n",
    "False postive rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89de6d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>FPR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.32</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Threshold  FPR\n",
       "1        0.98  0.0\n",
       "2        0.92  0.0\n",
       "3        0.87  0.2\n",
       "4        0.76  0.2\n",
       "5        0.74  0.4\n",
       "6        0.61  0.6\n",
       "7        0.57  0.6\n",
       "8        0.38  0.6\n",
       "9        0.34  0.8\n",
       "10       0.32  1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note, this is essentially copied from 1a with one modified line\n",
    "# Let's get the confusion matrices of 10 thresholds using the prediction values\n",
    "# Use list comprehension to generate a list of all the pred columns for every row in the data\n",
    "THRESHOLDS = [row[YPRED_COLUMN] for row in QUESTION_1_2_DATA]\n",
    "\n",
    "# Now let's make a 2D array that we are going to print for the answer\n",
    "_1b_ans = []\n",
    "\n",
    "# Loop through all the different thresholds we want to use\n",
    "for thresh in THRESHOLDS:\n",
    "    # retrieve the confusion matrix using this threshold\n",
    "    confusion_matrix = get_confusion_matrix(QUESTION_1_2_DATA, thresh)\n",
    "\n",
    "    # FPR is false positives / (false positives + true negatives)\n",
    "    fpr = float(confusion_matrix.false_positives) / float(confusion_matrix.false_positives + confusion_matrix.true_negatives)\n",
    "\n",
    "    # Add this entry to the data we want to display in the format: [threshold, TPR]\n",
    "    _1b_ans.append([thresh, fpr])\n",
    "\n",
    "# Now display the data\n",
    "cols = ['Threshold', 'FPR']\n",
    "rows = [str(i+1) for i in range(10)]\n",
    "pd.DataFrame(np.asarray(_1b_ans), index=rows, columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a40bf4",
   "metadata": {},
   "source": [
    "### 1.c: \n",
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45ef7448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.98</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.92</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Threshold  Accuracy\n",
       "1        0.98  1.000000\n",
       "2        0.92  1.000000\n",
       "3        0.87  0.666667\n",
       "4        0.76  0.750000\n",
       "5        0.74  0.600000\n",
       "6        0.61  0.500000\n",
       "7        0.57  0.571429\n",
       "8        0.38  0.625000\n",
       "9        0.34  0.555556\n",
       "10       0.32  0.500000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note, this is essentially copied from 1a with one modified line\n",
    "# Let's get the confusion matrices of 10 thresholds using the prediction values\n",
    "# Use list comprehension to generate a list of all the pred columns for every row in the data\n",
    "THRESHOLDS = [row[YPRED_COLUMN] for row in QUESTION_1_2_DATA]\n",
    "\n",
    "# Now let's make a 2D array that we are going to print for the answer\n",
    "_1c_ans = []\n",
    "\n",
    "# Loop through all the different thresholds we want to use\n",
    "for thresh in THRESHOLDS:\n",
    "    # retrieve the confusion matrix using this threshold\n",
    "    confusion_matrix = get_confusion_matrix(QUESTION_1_2_DATA, thresh)\n",
    "\n",
    "    # ACC is (True positives) / (True positives + False positives)\n",
    "    acc = float(confusion_matrix.true_positives) / float(confusion_matrix.true_positives + confusion_matrix.false_positives)\n",
    "\n",
    "    # Add this entry to the data we want to display in the format: [threshold, TPR]\n",
    "    _1c_ans.append([thresh, acc])\n",
    "\n",
    "# Now display the data\n",
    "cols = ['Threshold', 'Accuracy']\n",
    "rows = [str(i+1) for i in range(10)]\n",
    "pd.DataFrame(np.asarray(_1c_ans), index=rows, columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de49f175",
   "metadata": {},
   "source": [
    "Threshold the classifier output, Ypred, at each possible value (use a greater than equal to\n",
    "comparison).\n",
    "Report the results as a matrix/table with rows corresponding with the 10 thresholds and\n",
    "columns reporting the different thresholds, the true positive rate (TPR), false positive rate\n",
    "(FPR), and accuracy (ACC)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf620487",
   "metadata": {},
   "source": [
    "## (Question 2)\n",
    "se the results from Question 1 to plot the ROC curve for the data. Note, plot this\n",
    "curve using the standard plotting tools rather than any special library/package available in R,\n",
    "Python, or Matlab for making ROC plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00c38498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='tpr'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To plot the ROC curve, we plot a TPR vs FPR graph\n",
    "# Luckily, we can actually use our answers from before to snag all of our x,y pairs that we are going to plot\n",
    "# Define a list of points to plot\n",
    "_q2_x_points = []\n",
    "_q2_y_points = []\n",
    "\n",
    "# Loop through the data from before and construct our x and y points\n",
    "for row in _1a_ans:\n",
    "    tpr = row[1]\n",
    "    _q2_x_points.append(tpr)\n",
    "\n",
    "for row in _1b_ans:\n",
    "    fpr = row[1]\n",
    "    _q2_y_points.append(fpr)\n",
    "\n",
    "# Now construct the dataframe\n",
    "df = pd.DataFrame({\n",
    "    'tpr': _q2_x_points,\n",
    "    'fpr': _q2_y_points\n",
    "})\n",
    "\n",
    "df.style.set_caption(\"ROC Curve\")\n",
    "\n",
    "# Display the xy relationship\n",
    "df.plot.line(x='tpr', y='fpr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98a6cb8",
   "metadata": {},
   "source": [
    "## (Question 3) Classificaiton of Spam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8e8f99",
   "metadata": {},
   "source": [
    "### 3.a: \n",
    "Load in the spambase data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a466d214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency of 'make'</th>\n",
       "      <th>Frequency of 'address'</th>\n",
       "      <th>Frequency of 'all'</th>\n",
       "      <th>Frequency of '3d'</th>\n",
       "      <th>Frequency of 'our'</th>\n",
       "      <th>Frequency of 'over'</th>\n",
       "      <th>Frequency of 'remove'</th>\n",
       "      <th>Frequency of 'internet'</th>\n",
       "      <th>Frequency of 'order'</th>\n",
       "      <th>Frequency of 'mail'</th>\n",
       "      <th>...</th>\n",
       "      <th>Frequency of ';'</th>\n",
       "      <th>Frequency of '('</th>\n",
       "      <th>Frequency of '['</th>\n",
       "      <th>Frequency of '!'</th>\n",
       "      <th>Frequency of '$'</th>\n",
       "      <th>Frequency of '#'</th>\n",
       "      <th>Average Caps Running Length</th>\n",
       "      <th>Longest Caps Running Length</th>\n",
       "      <th>Total Caps Running Length</th>\n",
       "      <th>Is Spam?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.142</td>\n",
       "      <td>3</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.555</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.404</td>\n",
       "      <td>6</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.147</td>\n",
       "      <td>5</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.250</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4601 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Frequency of 'make'  Frequency of 'address'  Frequency of 'all'  \\\n",
       "0                    0.00                    0.64                0.64   \n",
       "1                    0.21                    0.28                0.50   \n",
       "2                    0.06                    0.00                0.71   \n",
       "3                    0.00                    0.00                0.00   \n",
       "4                    0.00                    0.00                0.00   \n",
       "...                   ...                     ...                 ...   \n",
       "4596                 0.31                    0.00                0.62   \n",
       "4597                 0.00                    0.00                0.00   \n",
       "4598                 0.30                    0.00                0.30   \n",
       "4599                 0.96                    0.00                0.00   \n",
       "4600                 0.00                    0.00                0.65   \n",
       "\n",
       "      Frequency of '3d'  Frequency of 'our'  Frequency of 'over'  \\\n",
       "0                   0.0                0.32                 0.00   \n",
       "1                   0.0                0.14                 0.28   \n",
       "2                   0.0                1.23                 0.19   \n",
       "3                   0.0                0.63                 0.00   \n",
       "4                   0.0                0.63                 0.00   \n",
       "...                 ...                 ...                  ...   \n",
       "4596                0.0                0.00                 0.31   \n",
       "4597                0.0                0.00                 0.00   \n",
       "4598                0.0                0.00                 0.00   \n",
       "4599                0.0                0.32                 0.00   \n",
       "4600                0.0                0.00                 0.00   \n",
       "\n",
       "      Frequency of 'remove'  Frequency of 'internet'  Frequency of 'order'  \\\n",
       "0                      0.00                     0.00                  0.00   \n",
       "1                      0.21                     0.07                  0.00   \n",
       "2                      0.19                     0.12                  0.64   \n",
       "3                      0.31                     0.63                  0.31   \n",
       "4                      0.31                     0.63                  0.31   \n",
       "...                     ...                      ...                   ...   \n",
       "4596                   0.00                     0.00                  0.00   \n",
       "4597                   0.00                     0.00                  0.00   \n",
       "4598                   0.00                     0.00                  0.00   \n",
       "4599                   0.00                     0.00                  0.00   \n",
       "4600                   0.00                     0.00                  0.00   \n",
       "\n",
       "      Frequency of 'mail'  ...  Frequency of ';'  Frequency of '('  \\\n",
       "0                    0.00  ...             0.000             0.000   \n",
       "1                    0.94  ...             0.000             0.132   \n",
       "2                    0.25  ...             0.010             0.143   \n",
       "3                    0.63  ...             0.000             0.137   \n",
       "4                    0.63  ...             0.000             0.135   \n",
       "...                   ...  ...               ...               ...   \n",
       "4596                 0.00  ...             0.000             0.232   \n",
       "4597                 0.00  ...             0.000             0.000   \n",
       "4598                 0.00  ...             0.102             0.718   \n",
       "4599                 0.00  ...             0.000             0.057   \n",
       "4600                 0.00  ...             0.000             0.000   \n",
       "\n",
       "      Frequency of '['  Frequency of '!'  Frequency of '$'  Frequency of '#'  \\\n",
       "0                  0.0             0.778             0.000             0.000   \n",
       "1                  0.0             0.372             0.180             0.048   \n",
       "2                  0.0             0.276             0.184             0.010   \n",
       "3                  0.0             0.137             0.000             0.000   \n",
       "4                  0.0             0.135             0.000             0.000   \n",
       "...                ...               ...               ...               ...   \n",
       "4596               0.0             0.000             0.000             0.000   \n",
       "4597               0.0             0.353             0.000             0.000   \n",
       "4598               0.0             0.000             0.000             0.000   \n",
       "4599               0.0             0.000             0.000             0.000   \n",
       "4600               0.0             0.125             0.000             0.000   \n",
       "\n",
       "      Average Caps Running Length  Longest Caps Running Length  \\\n",
       "0                           3.756                           61   \n",
       "1                           5.114                          101   \n",
       "2                           9.821                          485   \n",
       "3                           3.537                           40   \n",
       "4                           3.537                           40   \n",
       "...                           ...                          ...   \n",
       "4596                        1.142                            3   \n",
       "4597                        1.555                            4   \n",
       "4598                        1.404                            6   \n",
       "4599                        1.147                            5   \n",
       "4600                        1.250                            5   \n",
       "\n",
       "      Total Caps Running Length  Is Spam?  \n",
       "0                           278         1  \n",
       "1                          1028         1  \n",
       "2                          2259         1  \n",
       "3                           191         1  \n",
       "4                           191         1  \n",
       "...                         ...       ...  \n",
       "4596                         88         0  \n",
       "4597                         14         0  \n",
       "4598                        118         0  \n",
       "4599                         78         0  \n",
       "4600                         40         0  \n",
       "\n",
       "[4601 rows x 58 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some constants to define for ease of access of the data,\n",
    "# Automatically generated using a python script\n",
    "WORD_FREQ_MAKE = 'word_freq_make'\n",
    "WORD_FREQ_ADDRESS = 'word_freq_address'\n",
    "WORD_FREQ_ALL = 'word_freq_all'\n",
    "WORD_FREQ_3D = 'word_freq_3d'\n",
    "WORD_FREQ_OUR = 'word_freq_our'\n",
    "WORD_FREQ_OVER = 'word_freq_over'\n",
    "WORD_FREQ_REMOVE = 'word_freq_remove'\n",
    "WORD_FREQ_INTERNET = 'word_freq_internet'\n",
    "WORD_FREQ_ORDER = 'word_freq_order'\n",
    "WORD_FREQ_MAIL = 'word_freq_mail'\n",
    "WORD_FREQ_RECEIVE = 'word_freq_receive'\n",
    "WORD_FREQ_WILL = 'word_freq_will'\n",
    "WORD_FREQ_PEOPLE = 'word_freq_people'\n",
    "WORD_FREQ_REPORT = 'word_freq_report'\n",
    "WORD_FREQ_ADDRESSES = 'word_freq_addresses'\n",
    "WORD_FREQ_FREE = 'word_freq_free'\n",
    "WORD_FREQ_BUSINESS = 'word_freq_business'\n",
    "WORD_FREQ_EMAIL = 'word_freq_email'\n",
    "WORD_FREQ_YOU = 'word_freq_you'\n",
    "WORD_FREQ_CREDIT = 'word_freq_credit'\n",
    "WORD_FREQ_YOUR = 'word_freq_your'\n",
    "WORD_FREQ_FONT = 'word_freq_font'\n",
    "WORD_FREQ_000 = 'word_freq_000'\n",
    "WORD_FREQ_MONEY = 'word_freq_money'\n",
    "WORD_FREQ_HP = 'word_freq_hp'\n",
    "WORD_FREQ_HPL = 'word_freq_hpl'\n",
    "WORD_FREQ_GEORGE = 'word_freq_george'\n",
    "WORD_FREQ_650 = 'word_freq_650'\n",
    "WORD_FREQ_LAB = 'word_freq_lab'\n",
    "WORD_FREQ_LABS = 'word_freq_labs'\n",
    "WORD_FREQ_TELNET = 'word_freq_telnet'\n",
    "WORD_FREQ_857 = 'word_freq_857'\n",
    "WORD_FREQ_DATA = 'word_freq_data'\n",
    "WORD_FREQ_415 = 'word_freq_415'\n",
    "WORD_FREQ_85 = 'word_freq_85'\n",
    "WORD_FREQ_TECHNOLOGY = 'word_freq_technology'\n",
    "WORD_FREQ_1999 = 'word_freq_1999'\n",
    "WORD_FREQ_PARTS = 'word_freq_parts'\n",
    "WORD_FREQ_PM = 'word_freq_pm'\n",
    "WORD_FREQ_DIRECT = 'word_freq_direct'\n",
    "WORD_FREQ_CS = 'word_freq_cs'\n",
    "WORD_FREQ_MEETING = 'word_freq_meeting'\n",
    "WORD_FREQ_ORIGINAL = 'word_freq_original'\n",
    "WORD_FREQ_PROJECT = 'word_freq_project'\n",
    "WORD_FREQ_RE = 'word_freq_re'\n",
    "WORD_FREQ_EDU = 'word_freq_edu'\n",
    "WORD_FREQ_TABLE = 'word_freq_table'\n",
    "WORD_FREQ_CONFERENCE = 'word_freq_conference'\n",
    "CHAR_FREQ_SEMICOLON = 'char_freq_;'\n",
    "CHAR_FREQ_L_PARENTH = 'char_freq_('\n",
    "CHAR_FREQ_L_BRACKET = 'char_freq_['\n",
    "CHAR_FREQ_EXCLAIM_POINT = 'char_freq_!'\n",
    "CHAR_FREQ_DOLLAR_SIGN = 'char_freq_$'\n",
    "CHAR_FREQ_HASHTAG = 'char_freq_#'\n",
    "CAPITAL_RUN_LENGTH_AVERAGE = 'capital_run_length_average'\n",
    "CAPITAL_RUN_LENGTH_LONGEST = 'capital_run_length_longest'\n",
    "CAPITAL_RUN_LENGTH_TOTAL = 'capital_run_length_total'\n",
    "IS_SPAM = 'is_spam'\n",
    "\n",
    "SPAMBASE_COLUMNS = [\n",
    "\tWORD_FREQ_MAKE,\n",
    "\tWORD_FREQ_ADDRESS,\n",
    "\tWORD_FREQ_ALL,\n",
    "\tWORD_FREQ_3D,\n",
    "\tWORD_FREQ_OUR,\n",
    "\tWORD_FREQ_OVER,\n",
    "\tWORD_FREQ_REMOVE,\n",
    "\tWORD_FREQ_INTERNET,\n",
    "\tWORD_FREQ_ORDER,\n",
    "\tWORD_FREQ_MAIL,\n",
    "\tWORD_FREQ_RECEIVE,\n",
    "\tWORD_FREQ_WILL,\n",
    "\tWORD_FREQ_PEOPLE,\n",
    "\tWORD_FREQ_REPORT,\n",
    "\tWORD_FREQ_ADDRESSES,\n",
    "\tWORD_FREQ_FREE,\n",
    "\tWORD_FREQ_BUSINESS,\n",
    "\tWORD_FREQ_EMAIL,\n",
    "\tWORD_FREQ_YOU,\n",
    "\tWORD_FREQ_CREDIT,\n",
    "\tWORD_FREQ_YOUR,\n",
    "\tWORD_FREQ_FONT,\n",
    "\tWORD_FREQ_000,\n",
    "\tWORD_FREQ_MONEY,\n",
    "\tWORD_FREQ_HP,\n",
    "\tWORD_FREQ_HPL,\n",
    "\tWORD_FREQ_GEORGE,\n",
    "\tWORD_FREQ_650,\n",
    "\tWORD_FREQ_LAB,\n",
    "\tWORD_FREQ_LABS,\n",
    "\tWORD_FREQ_TELNET,\n",
    "\tWORD_FREQ_857,\n",
    "\tWORD_FREQ_DATA,\n",
    "\tWORD_FREQ_415,\n",
    "\tWORD_FREQ_85,\n",
    "\tWORD_FREQ_TECHNOLOGY,\n",
    "\tWORD_FREQ_1999,\n",
    "\tWORD_FREQ_PARTS,\n",
    "\tWORD_FREQ_PM,\n",
    "\tWORD_FREQ_DIRECT,\n",
    "\tWORD_FREQ_CS,\n",
    "\tWORD_FREQ_MEETING,\n",
    "\tWORD_FREQ_ORIGINAL,\n",
    "\tWORD_FREQ_PROJECT,\n",
    "\tWORD_FREQ_RE,\n",
    "\tWORD_FREQ_EDU,\n",
    "\tWORD_FREQ_TABLE,\n",
    "\tWORD_FREQ_CONFERENCE,\n",
    "\tCHAR_FREQ_SEMICOLON,\n",
    "\tCHAR_FREQ_L_PARENTH,\n",
    "\tCHAR_FREQ_L_BRACKET,\n",
    "\tCHAR_FREQ_EXCLAIM_POINT,\n",
    "\tCHAR_FREQ_DOLLAR_SIGN,\n",
    "\tCHAR_FREQ_HASHTAG,\n",
    "\tCAPITAL_RUN_LENGTH_AVERAGE,\n",
    "\tCAPITAL_RUN_LENGTH_LONGEST,\n",
    "\tCAPITAL_RUN_LENGTH_TOTAL,\n",
    "\tIS_SPAM\n",
    "]\n",
    "SPAMBASE_CLEAN_NAMES = {\n",
    "\tWORD_FREQ_MAKE: \"Frequency of 'make'\",\n",
    "\tWORD_FREQ_ADDRESS: \"Frequency of 'address'\",\n",
    "\tWORD_FREQ_ALL: \"Frequency of 'all'\",\n",
    "\tWORD_FREQ_3D: \"Frequency of '3d'\",\n",
    "\tWORD_FREQ_OUR: \"Frequency of 'our'\",\n",
    "\tWORD_FREQ_OVER: \"Frequency of 'over'\",\n",
    "\tWORD_FREQ_REMOVE: \"Frequency of 'remove'\",\n",
    "\tWORD_FREQ_INTERNET: \"Frequency of 'internet'\",\n",
    "\tWORD_FREQ_ORDER: \"Frequency of 'order'\",\n",
    "\tWORD_FREQ_MAIL: \"Frequency of 'mail'\",\n",
    "\tWORD_FREQ_RECEIVE: \"Frequency of 'receive'\",\n",
    "\tWORD_FREQ_WILL: \"Frequency of 'will'\",\n",
    "\tWORD_FREQ_PEOPLE: \"Frequency of 'people'\",\n",
    "\tWORD_FREQ_REPORT: \"Frequency of 'report'\",\n",
    "\tWORD_FREQ_ADDRESSES: \"Frequency of 'addresses'\",\n",
    "\tWORD_FREQ_FREE: \"Frequency of 'free'\",\n",
    "\tWORD_FREQ_BUSINESS: \"Frequency of 'business'\",\n",
    "\tWORD_FREQ_EMAIL: \"Frequency of 'email'\",\n",
    "\tWORD_FREQ_YOU: \"Frequency of 'you'\",\n",
    "\tWORD_FREQ_CREDIT: \"Frequency of 'credit'\",\n",
    "\tWORD_FREQ_YOUR: \"Frequency of 'your'\",\n",
    "\tWORD_FREQ_FONT: \"Frequency of 'font'\",\n",
    "\tWORD_FREQ_000: \"Frequency of '000'\",\n",
    "\tWORD_FREQ_MONEY: \"Frequency of 'money'\",\n",
    "\tWORD_FREQ_HP: \"Frequency of 'hp'\",\n",
    "\tWORD_FREQ_HPL: \"Frequency of 'hpl'\",\n",
    "\tWORD_FREQ_GEORGE: \"Frequency of 'george'\",\n",
    "\tWORD_FREQ_650: \"Frequency of '650'\",\n",
    "\tWORD_FREQ_LAB: \"Frequency of 'lab'\",\n",
    "\tWORD_FREQ_LABS: \"Frequency of 'labs'\",\n",
    "\tWORD_FREQ_TELNET: \"Frequency of 'telnet'\",\n",
    "\tWORD_FREQ_857: \"Frequency of '857'\",\n",
    "\tWORD_FREQ_DATA: \"Frequency of 'data'\",\n",
    "\tWORD_FREQ_415: \"Frequency of '415'\",\n",
    "\tWORD_FREQ_85: \"Frequency of '85'\",\n",
    "\tWORD_FREQ_TECHNOLOGY: \"Frequency of 'technology'\",\n",
    "\tWORD_FREQ_1999: \"Frequency of '1999'\",\n",
    "\tWORD_FREQ_PARTS: \"Frequency of 'parts'\",\n",
    "\tWORD_FREQ_PM: \"Frequency of 'pm'\",\n",
    "\tWORD_FREQ_DIRECT: \"Frequency of 'direct'\",\n",
    "\tWORD_FREQ_CS: \"Frequency of 'cs'\",\n",
    "\tWORD_FREQ_MEETING: \"Frequency of 'meeting'\",\n",
    "\tWORD_FREQ_ORIGINAL: \"Frequency of 'original'\",\n",
    "\tWORD_FREQ_PROJECT: \"Frequency of 'project'\",\n",
    "\tWORD_FREQ_RE: \"Frequency of 're'\",\n",
    "\tWORD_FREQ_EDU: \"Frequency of 'edu'\",\n",
    "\tWORD_FREQ_TABLE: \"Frequency of 'table'\",\n",
    "\tWORD_FREQ_CONFERENCE: \"Frequency of 'conference'\",\n",
    "\tCHAR_FREQ_SEMICOLON: \"Frequency of ';'\",\n",
    "\tCHAR_FREQ_L_PARENTH: \"Frequency of '('\",\n",
    "\tCHAR_FREQ_L_BRACKET: \"Frequency of '['\",\n",
    "\tCHAR_FREQ_EXCLAIM_POINT: \"Frequency of '!'\",\n",
    "\tCHAR_FREQ_DOLLAR_SIGN: \"Frequency of '$'\",\n",
    "\tCHAR_FREQ_HASHTAG: \"Frequency of '#'\",\n",
    "\tCAPITAL_RUN_LENGTH_AVERAGE: \"Average Caps Running Length\",\n",
    "\tCAPITAL_RUN_LENGTH_LONGEST: \"Longest Caps Running Length\",\n",
    "\tCAPITAL_RUN_LENGTH_TOTAL: \"Total Caps Running Length\",\n",
    "\tIS_SPAM: \"Is Spam?\"\n",
    "}\n",
    "\n",
    "SPAMBASE_CLEAN_COLUMNS = [SPAMBASE_CLEAN_NAMES[var] for var in SPAMBASE_COLUMNS]\n",
    "# Just like other assignments, read the CSV\n",
    "SPAMBASE_CSV = 'spambase.data'\n",
    "SPAMBASE_DATA = pd.read_csv(SPAMBASE_CSV, names=SPAMBASE_CLEAN_COLUMNS)\n",
    "SPAMBASE_DATA.head(n=len(SPAMBASE_DATA.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6584b8",
   "metadata": {},
   "source": [
    "### 3.b: \n",
    "To see whether a classifier is actually working, we should compare it to a constant classifier\n",
    "which always predicts the same class, no matter what the input features actually are"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fca1dc",
   "metadata": {},
   "source": [
    "#### 3.b.i:\n",
    "What fraction of the e-mails are actually spam?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5bb5f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fraction of spam emails to total emails is 1813 / 4601 (39.40%)\n"
     ]
    }
   ],
   "source": [
    "# We just need spam / total data\n",
    "total_data = len(SPAMBASE_DATA.values)\n",
    "\n",
    "num_spam = 0\n",
    "# Loop through all the rows, is it spam?\n",
    "SPAMBASE_DATA.reset_index()\n",
    "for index, row in SPAMBASE_DATA.iterrows():\n",
    "\tis_spam = row[SPAMBASE_COLUMNS.index(IS_SPAM)] == 1\n",
    "\tif is_spam:\n",
    "\t\tnum_spam += 1\n",
    "\n",
    "perc = float(num_spam) / float(total_data)\n",
    "print(f\"The fraction of spam emails to total emails is {num_spam} / {total_data} ({perc*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6c8949",
   "metadata": {},
   "source": [
    "#### 3.b.ii: \n",
    "What should the constant classifier predict?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b8df0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The constant classifier predicted is it will not be spam\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn import preprocessing\n",
    "\n",
    "x = SPAMBASE_DATA  #load data\n",
    "y = SPAMBASE_DATA[['Is Spam?']] #load the column 'Is Spam?'\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(x, y, random_state=0) #parse data so it can be used for training and testing\n",
    "\n",
    "clf = DummyClassifier(strategy='most_frequent')\n",
    "\n",
    "clf.fit(X_train1, y_train1) #fit the training model\n",
    "\n",
    "\n",
    "DummyClassifier(strategy='stratified')\n",
    "\n",
    "clf.fit(X_test1,y_test1) #fit the testing model\n",
    "\n",
    "\n",
    "if (clf.predict(y_test1)[0] & clf.predict(y_train1)[0]) == 0:\n",
    "    print(\"The constant classifier predicted is it will not be spam\")\n",
    "else:\n",
    "    print(\"The constant classifier predicted will be spam\")\n",
    "\n",
    "#just for debugging purposes\n",
    "#trainPercent = y_train.value_counts(normalize=True)[0]\n",
    "#print( f\" Training Percent predicts { trainPercent * 100:.2f}% will not be spam\"  )\n",
    "\n",
    "#testPercent=y_test.value_counts(normalize=True)[0]\n",
    "#print( f\" Testing Percent predicts { testPercent * 100:.2f}% will not be spam\"  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff390c1",
   "metadata": {},
   "source": [
    "#### 3.b.iii: \n",
    "What is the error rate of the constant classifier? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1fed058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The error rate of the constant classifier is 39.97% \n"
     ]
    }
   ],
   "source": [
    "y_pred1 = clf.predict(X_test1)\n",
    "errorRate = 1- metrics.accuracy_score(y_test1,y_pred1)\n",
    "print(f\" The error rate of the constant classifier is { errorRate * 100:.2f}% \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1e5283",
   "metadata": {},
   "source": [
    "### 3.c: Model Selection and Evaluation: Three-fold Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08f4f87",
   "metadata": {},
   "source": [
    "Split the data into training, validation and test sets with 60, 20, and 20% of the data\n",
    "respectively. Make sure to split the data such that the distribution of class labels is\n",
    "approximately equal across splits - “stratify”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abb1405",
   "metadata": {},
   "source": [
    "#### 3.c.i:\n",
    "What fraction of each set: training, validation, and test sets are spam?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4ec7c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fraction of spam emails for the training test set are 1087 / 2760 (39.38%)\n",
      "\n",
      "\n",
      "The fraction of spam emails for the validation test set are 363 / 920 (39.46%)\n",
      "\n",
      "\n",
      "The fraction of spam emails for the testing test set are 363 / 921 (39.41%)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#delcare splits\n",
    "train_ratio = 0.60\n",
    "validation_ratio = 0.20\n",
    "test_ratio = 0.20\n",
    "\n",
    "#import data\n",
    "x_in = SPAMBASE_DATA\n",
    "y_in = SPAMBASE_DATA[['Is Spam?']]\n",
    "\n",
    "X_train1, X_test, y_train1, y_test = train_test_split(x_in, y_in, test_size=test_ratio, stratify = y_in)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train1, y_train1, \n",
    "                                                      test_size = validation_ratio/(train_ratio + test_ratio), \n",
    "                                                      stratify = y_train1 )\n",
    "\n",
    "#count and display percent of training data that is spam\n",
    "total_data_train = len(y_train.values)\n",
    "count_train = 0\n",
    "for row in y_train.values:\n",
    "    if(row == 1):\n",
    "        count_train = count_train +1\n",
    "perc = float(count_train) / float(total_data_train)\n",
    "print(f\"The fraction of spam emails for the training test set are {count_train} / {total_data_train} ({perc * 100:.2f}%)\")\n",
    "print('\\n')\n",
    "\n",
    "#count and display percent of validation data that is spam\n",
    "total_data_valids = len(y_valid.values)\n",
    "count_valid = 0\n",
    "for row in y_valid.values:\n",
    "    if(row == 1):\n",
    "        count_valid = count_valid +1\n",
    "\n",
    "perc1 = float(count_valid) / float(total_data_valids)\n",
    "print(f\"The fraction of spam emails for the validation test set are {count_valid} / {total_data_valids} ({perc1 * 100:.2f}%)\")\n",
    "print('\\n')\n",
    "\n",
    "#count and display percent of testing data that is spam\n",
    "total_data_test = len(y_test.values)\n",
    "count_test = 0\n",
    "for row in y_test.values:\n",
    "    if(row == 1):\n",
    "        count_test = count_test +1\n",
    "\n",
    "perc2 = float(count_test) / float(total_data_test)\n",
    "print(f\"The fraction of spam emails for the testing test set are {count_test} / {total_data_test} ({perc2 * 100:.2f}%)\")\n",
    "print('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd62216",
   "metadata": {},
   "source": [
    "#### 3.c.ii:\n",
    "Check that two predictor variables in the data set have approximatly the same distribution in each of the sets\n",
    "Set the seed for the random generator to ”5”, Python - random state and R - set.seed(5).\n",
    "\n",
    "Helpful functions: R - sample, Matlab - cvpartition, Python - train test split from\n",
    "sklearn.model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "efe7cb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 0             1             2             3             4   \\\n",
      "count  3.680000e+03  3.680000e+03  3.680000e+03  3.680000e+03  3.680000e+03   \n",
      "mean  -7.759494e-17 -1.687660e-16 -1.580258e-16 -2.302808e-16  6.537947e-16   \n",
      "std    1.000136e+00  1.000136e+00  1.000136e+00  1.000136e+00  1.000136e+00   \n",
      "min   -3.404178e-01 -1.651654e-01 -5.567860e-01 -5.155608e-02 -4.642446e-01   \n",
      "25%   -3.404178e-01 -1.651654e-01 -5.567860e-01 -5.155608e-02 -4.642446e-01   \n",
      "50%   -3.404178e-01 -1.651654e-01 -5.567860e-01 -5.155608e-02 -4.642446e-01   \n",
      "75%   -3.404178e-01 -1.651654e-01  2.804511e-01 -5.155608e-02  1.153695e-01   \n",
      "max    1.410238e+01  1.170815e+01  9.373235e+00  2.740681e+01  1.439766e+01   \n",
      "\n",
      "                 5             6             7             8             9   \\\n",
      "count  3.680000e+03  3.680000e+03  3.680000e+03  3.680000e+03  3.680000e+03   \n",
      "mean  -1.035705e-16 -7.868102e-17  2.102787e-17  9.681265e-17 -2.624410e-16   \n",
      "std    1.000136e+00  1.000136e+00  1.000136e+00  1.000136e+00  1.000136e+00   \n",
      "min   -3.455830e-01 -2.899450e-01 -2.592138e-01 -3.270547e-01 -3.635827e-01   \n",
      "25%   -3.455830e-01 -2.899450e-01 -2.592138e-01 -3.270547e-01 -3.635827e-01   \n",
      "50%   -3.455830e-01 -2.899450e-01 -2.592138e-01 -3.270547e-01 -3.635827e-01   \n",
      "75%   -3.455830e-01 -2.899450e-01 -2.592138e-01 -3.270547e-01 -1.241760e-01   \n",
      "max    2.094734e+01  1.764922e+01  2.669375e+01  1.193652e+01  2.683901e+01   \n",
      "\n",
      "       ...            48            49            50            51  \\\n",
      "count  ...  3.680000e+03  3.680000e+03  3.680000e+03  3.680000e+03   \n",
      "mean   ... -1.055164e-16 -4.452960e-17 -1.496267e-15  8.791277e-17   \n",
      "std    ...  1.000136e+00  1.000136e+00  1.000136e+00  1.000136e+00   \n",
      "min    ... -1.560580e-01 -5.086669e-01 -1.487191e-01 -3.188382e-01   \n",
      "25%    ... -1.560580e-01 -5.086669e-01 -1.487191e-01 -3.188382e-01   \n",
      "50%    ... -1.560580e-01 -2.704635e-01 -1.487191e-01 -3.188382e-01   \n",
      "75%    ... -1.560580e-01  1.738776e-01 -1.487191e-01  5.336741e-02   \n",
      "max    ...  1.723440e+01  3.522918e+01  3.414596e+01  3.742821e+01   \n",
      "\n",
      "                 52            53            54            55            56  \\\n",
      "count  3.680000e+03  3.680000e+03  3.680000e+03  3.680000e+03  3.680000e+03   \n",
      "mean   4.055029e-16  1.709457e-16  2.404478e-17 -4.427316e-17 -3.934051e-17   \n",
      "std    1.000136e+00  1.000136e+00  1.000136e+00  1.000136e+00  1.000136e+00   \n",
      "min   -3.627793e-01 -9.939431e-02 -1.291017e-01 -2.488769e-01 -4.551971e-01   \n",
      "25%   -3.627793e-01 -9.939431e-02 -1.119152e-01 -2.251796e-01 -4.011329e-01   \n",
      "50%   -3.627793e-01 -9.939431e-02 -9.099895e-02 -1.825245e-01 -3.057255e-01   \n",
      "75%   -1.005748e-01 -9.939431e-02 -4.839065e-02 -4.981969e-02 -3.500692e-02   \n",
      "max    2.018894e+01  4.332163e+01  3.273717e+01  4.708883e+01  2.473236e+01   \n",
      "\n",
      "                 57  \n",
      "count  3.680000e+03  \n",
      "mean  -2.432233e-16  \n",
      "std    1.000136e+00  \n",
      "min   -8.141873e-01  \n",
      "25%   -8.141873e-01  \n",
      "50%   -8.141873e-01  \n",
      "75%    1.228219e+00  \n",
      "max    1.228219e+00  \n",
      "\n",
      "[8 rows x 58 columns]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.linear_model import LinearRegression as lm\n",
    "# split into train test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_in, y_in, test_size = 0.2, random_state = 5)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_in, y_in, test_size = 0.2, random_state = 5)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(pd.DataFrame(X_train).describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d6470d",
   "metadata": {},
   "source": [
    "### 3.d: Scale the predictor data to values between [0,1] using MinMax scalling.\n",
    "make sure to use training data set to set scaling parameters and apply those parameters to\n",
    "scaling the validation and testing data.\n",
    "Helpful functions: R - preProcess from caret, Python - MinMaxScaler from\n",
    "sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b51543a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.12334802e-01, 0.00000000e+00, 1.00000000e-01, ...,\n",
       "        1.10132159e-03, 4.10353535e-03, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        2.00240288e-04, 6.94444444e-04, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 4.90196078e-01, ...,\n",
       "        2.00240288e-04, 6.31313131e-04, 0.00000000e+00],\n",
       "       ...,\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        6.00720865e-04, 1.76767677e-03, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        1.10132159e-03, 4.29292929e-03, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.39215686e-01, ...,\n",
       "        5.70684822e-03, 5.64393939e-02, 1.00000000e+00]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "scaler.transform(pd.DataFrame(X_valid).values)\n",
    "scaler.transform(pd.DataFrame(X_test).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac052618",
   "metadata": {},
   "source": [
    "### 3.e: KNN - K Nearest Neighbors\n",
    "For k of odd values, 5-51, fit a k-nearest-neighbor classifier to the training data. Evaluate these classifiers on the validation data. Select the best value of k (minimizes the validation error). Retrain the best model on train+validation and evaluate it on the testing data.\n",
    "\n",
    "Helpful functions: Python- KNeighborsClassifier from sklearn.neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6d2fca",
   "metadata": {},
   "source": [
    "#### 3.e.i:\n",
    "Report the training, validation and test error in a plot with x-axis as values of k and the y-axis error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b7edd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delcare split\n",
    "train_ratio = 0.60\n",
    "\n",
    "#import data\n",
    "x_in1 = SPAMBASE_DATA  #load data\n",
    "y_in1 = SPAMBASE_DATA[['Is Spam?']] #load the column 'Is Spam?'\n",
    "\n",
    "#create testing, training and validation data splits\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_in, y_in, test_size=test_ratio, stratify = y_in)\n",
    "\n",
    "\n",
    "#create odd #'s \n",
    "k_range=[]\n",
    "for i in range(5,52):\n",
    "    if( i % 2 != 0):\n",
    "        k_range.append(i)\n",
    "        \n",
    "performance=[]\n",
    "\n",
    "#lean the KNN classifier w/ num_neighbors = k on training data\n",
    "for k in k_range:\n",
    "    #Create KNN Classifier\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "\n",
    "    #Train the model using the training sets\n",
    "    knn.fit(X_train, y_train.values.ravel())\n",
    "    \n",
    "    #Predict the response for test dataset\n",
    "    y_TrainVal = knn.predict(X_train )\n",
    "    \n",
    "    performance.append(metrics.accuracy_score(y_train, y_TrainVal))\n",
    "\n",
    "#find the max value from the perfromacnce values    \n",
    "best = np.max(performance)\n",
    "\n",
    "#find the locations of the max value\n",
    "key_loc = np.asarray(np.where(performance == best))\n",
    "\n",
    "#store value of max value form the keys\n",
    "loc = np.asarray(key_loc)\n",
    "\n",
    "ranger = np.asarray(k_range)\n",
    "\n",
    "#loop through and find best value\n",
    "for i in key_loc:\n",
    "    temp = ranger[i]\n",
    "    #print(\"The value of k that was selected as the best are: \",str(temp)[1:-1])\n",
    "\n",
    "#store bestK value\n",
    "bestK = int(temp)\n",
    "\n",
    "perf2=[]\n",
    "\n",
    "#learn a KNN w/ num_neighbors = bestK -k on training and validation data\n",
    "for k in k_range:\n",
    "    #Create KNN Classifier\n",
    "    if((bestK -k) !=0):\n",
    "        knn = KNeighborsClassifier(n_neighbors = abs(bestK - k))\n",
    "    \n",
    "        #Train the model using the training and validation sets\n",
    "        knn.fit(X_train, y_train.values.ravel())\n",
    "    \n",
    "        #Predict the response for test dataset\n",
    "        y_predTest = knn.predict(X_test)\n",
    "    \n",
    "        perf2.append(metrics.accuracy_score(y_test, y_predTest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f56c10ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x13ef7ffda88>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#create plot of training data and the validation & test data\n",
    "\n",
    "plt.plot(range(0,24),np.asarray(performance),label=\"training\")\n",
    "plt.plot(range(1,24),np.asarray(perf2),label=\"validation and test\")\n",
    "\n",
    "plt.title(\"Error rate vs. K Value\")\n",
    "\n",
    "plt.xlabel('K Values')\n",
    "\n",
    "plt.ylabel('Error')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6823b3",
   "metadata": {},
   "source": [
    "#### 3.e.ii:\n",
    "Report which value of k was selected as best. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46f67a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of k that was selected as the best is:  5\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ranger = np.asarray(k_range)\n",
    "\n",
    "for i in key_loc:\n",
    "    temp = ranger[i]\n",
    "    print(\"The value of k that was selected as the best is: \",str(temp)[1:-1])\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c29077",
   "metadata": {},
   "source": [
    "### 3.f: Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ae9f23",
   "metadata": {},
   "source": [
    "#### 3.f.i:\n",
    "Construct a classification tree to predict spam on the training data. Then print out the tree found\n",
    "Helpful functions: Python - DecisionTreeClassifier, export=graphviz from sklearn.tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e44636a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of feature_names, 57 does not match number of features, 58",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11328/2802975724.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;31m# Note: SPAMBASE_CLEAN_COLUMNS[:-1] for feature_names since we don't include the last column that we removed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m dot_data = tree.export_graphviz(clf, out_file= None, feature_names= SPAMBASE_CLEAN_COLUMNS[:-1],\n\u001b[1;32m---> 34\u001b[1;33m                                 class_names = ['0','1'], filled = True, rounded=True)\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSource\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\_School_Software\\anaconda3\\envs\\cs4821\\lib\\site-packages\\sklearn\\tree\\_export.py\u001b[0m in \u001b[0;36mexport_graphviz\u001b[1;34m(decision_tree, out_file, max_depth, feature_names, class_names, label, filled, leaves_parallel, impurity, node_ids, proportion, rotate, rounded, special_characters, precision, fontname)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mfontname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfontname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         )\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mexporter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecision_tree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreturn_string\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\_School_Software\\anaconda3\\envs\\cs4821\\lib\\site-packages\\sklearn\\tree\\_export.py\u001b[0m in \u001b[0;36mexport\u001b[1;34m(self, decision_tree)\u001b[0m\n\u001b[0;32m    452\u001b[0m                 raise ValueError(\n\u001b[0;32m    453\u001b[0m                     \u001b[1;34m\"Length of feature_names, %d does not match number of features, %d\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m                     \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecision_tree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m                 )\n\u001b[0;32m    456\u001b[0m         \u001b[1;31m# each part writes to out_file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length of feature_names, 57 does not match number of features, 58"
     ]
    }
   ],
   "source": [
    "#!pip install pydotplus\n",
    "#!pip install graphviz\n",
    "#!pip install six\n",
    "import pydotplus\n",
    "import graphviz\n",
    "import six\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image\n",
    "\n",
    "master_data = SPAMBASE_DATA\n",
    "\n",
    "master_train_data, master_test_data = train_test_split(master_data, test_size=0.3, random_state=0)\n",
    "\n",
    "# Extract the is spam column\n",
    "train_extracted_is_spam_col = master_train_data['Is Spam?']\n",
    "test_extracted_is_spam_col = master_train_data['Is Spam?']\n",
    "\n",
    "# Remove it\n",
    "master_train_data.drop(columns=['Is Spam?'])\n",
    "master_test_data.drop(columns=['Is Spam?'])\n",
    "\n",
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.max_depth=3\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf.fit(master_train_data, train_extracted_is_spam_col)\n",
    "\n",
    "# Note: SPAMBASE_CLEAN_COLUMNS[:-1] for feature_names since we don't include the last column that we removed\n",
    "dot_data = tree.export_graphviz(clf, out_file= None, feature_names= SPAMBASE_CLEAN_COLUMNS[:-1],\n",
    "                                class_names = ['0','1'], filled = True, rounded=True)\n",
    "                                \n",
    "graph = graphviz.Source(dot_data)  \n",
    "\n",
    "graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5061e279",
   "metadata": {},
   "source": [
    "#### 3.f.ii: \n",
    "Which selection criteria is used by default when learning the tree model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe37d1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "927064f8",
   "metadata": {},
   "source": [
    "### 3.g: Naive Bayes\n",
    "Use a Naive Bayes classifier to predict whether the emails are spam. Report the training and testing accuracy, sensitivity, specificity, and AUC. \n",
    "Helpful functions: Python - GaussianNB from sklearn.naive bayes. \n",
    "Python - sklearn.metrics library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "897361ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-set accuracy score: 0.8045\n",
      "Sensitivity : 0.9338\n",
      "Specificity : 0.7165\n",
      "ROC AUC : 0.8699\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#load data in x and column of interest in y\n",
    "XG = SPAMBASE_DATA\n",
    "YG = SPAMBASE_DATA[['Is Spam?']]\n",
    "\n",
    "# Split off the data\n",
    "_3g_train, _3g_test = train_test_split(XG, test_size=.3, random_state=0)\n",
    "\n",
    "# Extract the actual values from the data, these aren't used in predicts\n",
    "extracted_spam_train = _3g_train[\"Is Spam?\"]\n",
    "extracted_spam_test = _3g_test[\"Is Spam?\"]\n",
    "\n",
    "# Drop them\n",
    "_3g_train = _3g_train.drop(columns=[\"Is Spam?\"])\n",
    "_3g_test = _3g_test.drop(columns=[\"Is Spam?\"])\n",
    "\n",
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "# Train the scaler using the training data\n",
    "sc.fit(_3g_train)\n",
    "\n",
    "# Transform all the data\n",
    "scaled_3g_train = sc.transform(_3g_train)\n",
    "scaled_3g_test = sc.transform(_3g_test)\n",
    "\n",
    "# Training the Naive Bayes model on the Training set\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Train the model using the draining data, and the actual training values\n",
    "gnb.fit(scaled_3g_train, extracted_spam_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_predG = gnb.predict(scaled_3g_test)\n",
    "\n",
    "print('Test-set accuracy score: {0:0.04f}'. format(accuracy_score(extracted_spam_test, y_predG)))\n",
    "\n",
    "\n",
    "CM = confusion_matrix(extracted_spam_test, y_predG)\n",
    "\n",
    "TN = CM[0][0]\n",
    "FN = CM[1][0]\n",
    "TP = CM[1][1]\n",
    "FP = CM[0][1]\n",
    "\n",
    "recall = TP / float(TP + FN)\n",
    "\n",
    "print('Sensitivity : {0:0.4f}'.format(recall))\n",
    "\n",
    "spec = TN / float(TN+FP) \n",
    "print('Specificity : {0:0.4f}'.format(spec))\n",
    "\n",
    "y_pred1 = gnb.predict_proba(scaled_3g_test)[:, 1]\n",
    "\n",
    "ROC_AUC = roc_auc_score(extracted_spam_test, y_pred1)\n",
    "\n",
    "print('ROC AUC : {:.4f}'.format(ROC_AUC))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075b4337",
   "metadata": {},
   "source": [
    "### 3H Model Selection / Evaluation\n",
    "Model Selection / Evaluation: Grid Search with Cross-Validation - KFolds.\n",
    "We will now incorporate cross-validation into the model selection and evaluation process and use it for the next two parts of the question, Q3(i) and Q3(j).\n",
    "First, split out the test set with 20% of the data. \n",
    "Helpful functions: Python - train test split from sklearn.model _selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9932b01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data in x and column of interest in y\n",
    "XH = SPAMBASE_DATA\n",
    "YH = SPAMBASE_DATA[['Is Spam?']]\n",
    "\n",
    "# Split off the data\n",
    "_3h_train, _3h_test = train_test_split(XH, test_size=.2, random_state=0)\n",
    "\n",
    "# Extract the actual values from the data, these aren't used in predicts\n",
    "extracted_spam_train = _3h_train[\"Is Spam?\"]\n",
    "extracted_spam_test = _3h_test[\"Is Spam?\"]\n",
    "\n",
    "# Drop them\n",
    "_3h_train = _3h_train.drop(columns=[\"Is Spam?\"])\n",
    "_3h_test = _3h_test.drop(columns=[\"Is Spam?\"])\n",
    "\n",
    "  \n",
    "# Feature Scaling\n",
    "mms = MinMaxScaler()\n",
    "# Train the scaler using the training data\n",
    "mms.fit(_3h_train)\n",
    "\n",
    "# Transform all the data\n",
    "scaled_3h_train = mms.transform(_3h_train)\n",
    "scaled_3h_test = mms.transform(_3h_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82c6139",
   "metadata": {},
   "source": [
    "### 3.i: Support Vector Machines\n",
    "Learn SVM modesl to predict spam using 10-fold cross-validation on the train+validaiton data to select the best parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e1e761",
   "metadata": {},
   "source": [
    "#### 3.i.1: \n",
    "The remaining train+validation set, from Q3(h), will be split using 10-fold cross-validation. You will do cross-validation by hand, that is with the functions:\n",
    "Helpful functions: Python - StratifiedKFold from sklearn.model selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "2facaa4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 182  183  184 ... 4598 4599 4600] TEST: [   0    1    2    3    4    5    6    7    8    9   10   11   12   13\n",
      "   14   15   16   17   18   19   20   21   22   23   24   25   26   27\n",
      "   28   29   30   31   32   33   34   35   36   37   38   39   40   41\n",
      "   42   43   44   45   46   47   48   49   50   51   52   53   54   55\n",
      "   56   57   58   59   60   61   62   63   64   65   66   67   68   69\n",
      "   70   71   72   73   74   75   76   77   78   79   80   81   82   83\n",
      "   84   85   86   87   88   89   90   91   92   93   94   95   96   97\n",
      "   98   99  100  101  102  103  104  105  106  107  108  109  110  111\n",
      "  112  113  114  115  116  117  118  119  120  121  122  123  124  125\n",
      "  126  127  128  129  130  131  132  133  134  135  136  137  138  139\n",
      "  140  141  142  143  144  145  146  147  148  149  150  151  152  153\n",
      "  154  155  156  157  158  159  160  161  162  163  164  165  166  167\n",
      "  168  169  170  171  172  173  174  175  176  177  178  179  180  181\n",
      " 1813 1814 1815 1816 1817 1818 1819 1820 1821 1822 1823 1824 1825 1826\n",
      " 1827 1828 1829 1830 1831 1832 1833 1834 1835 1836 1837 1838 1839 1840\n",
      " 1841 1842 1843 1844 1845 1846 1847 1848 1849 1850 1851 1852 1853 1854\n",
      " 1855 1856 1857 1858 1859 1860 1861 1862 1863 1864 1865 1866 1867 1868\n",
      " 1869 1870 1871 1872 1873 1874 1875 1876 1877 1878 1879 1880 1881 1882\n",
      " 1883 1884 1885 1886 1887 1888 1889 1890 1891 1892 1893 1894 1895 1896\n",
      " 1897 1898 1899 1900 1901 1902 1903 1904 1905 1906 1907 1908 1909 1910\n",
      " 1911 1912 1913 1914 1915 1916 1917 1918 1919 1920 1921 1922 1923 1924\n",
      " 1925 1926 1927 1928 1929 1930 1931 1932 1933 1934 1935 1936 1937 1938\n",
      " 1939 1940 1941 1942 1943 1944 1945 1946 1947 1948 1949 1950 1951 1952\n",
      " 1953 1954 1955 1956 1957 1958 1959 1960 1961 1962 1963 1964 1965 1966\n",
      " 1967 1968 1969 1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980\n",
      " 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994\n",
      " 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008\n",
      " 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022\n",
      " 2023 2024 2025 2026 2027 2028 2029 2030 2031 2032 2033 2034 2035 2036\n",
      " 2037 2038 2039 2040 2041 2042 2043 2044 2045 2046 2047 2048 2049 2050\n",
      " 2051 2052 2053 2054 2055 2056 2057 2058 2059 2060 2061 2062 2063 2064\n",
      " 2065 2066 2067 2068 2069 2070 2071 2072 2073 2074 2075 2076 2077 2078\n",
      " 2079 2080 2081 2082 2083 2084 2085 2086 2087 2088 2089 2090 2091]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'[182, 185, 189, 192, 195, 202, 203, 214, 217, 218, 220, 221, 223, 224, 227, 241, 245, 246, 248, 252, 253, 263, 269, 271, 283, 286, 291, 294, 298, 302, 304, 308, 311, 314, 325, 326, 333, 345, 347, 348, 352, 378, 379, 381, 383, 402, 405, 406, 408, 410, 415, 429, 453, 462, 463, 465, 470, 480, 481, 485, 487, 489, 491, 496, 499, 500, 501, 502, 507, 514, 520, 521, 526, 528, 530, 531, 533, 534, 536, 541, 543, 545, 548, 553, 555, 556, 559, 562, 567, 569, 575, 576, 578, 581, 582, 584, 599, 619, 620, 621, 622, 629, 634, 636, 638, 639, 648, 651, 661, 666, 667, 668, 675, 678, 680, 683, 684, 685, 690, 704, 708, 712, 716, 720, 727, 731, 735, 748, 751, 773, 775, 776, 780, 788, 799, 803, 806, 809, 812, 817, 825, 829, 831, 836, 842, 847, 849, 854, 861, 866, 867, 872, 873, 878, 882, 883, 888, 891, 895, 896, 898, 900, 906, 910, 917, 918, 927, 933, 938, 939, 942, 949, 962, 965, 971, 976, 977, 979, 980, 982, 991, 995, 1001, 1002, 1005, 1009, 1011, 1012, 1021, 1022, 1043, 1051, 1065, 1068, 1069, 1073, 1077, 1082, 1084, 1085, 1091, 1095, 1098, 1104, 1109, 1114, 1115, 1116, 1118, 1127, 1141, 1144, 1160, 1161, 1163, 1170, 1172, 1176, 1177, 1190, 1196, 1202, 1203, 1206, 1220, 1230, 1232, 1237, 1239, 1246, 1256, 1259, 1261, 1262, 1267, 1271, 1272, 1273, 1275, 1281, 1290, 1299, 1300, 1303, 1319, 1324, 1327, 1328, 1329, 1336, 1343, 1351, 1357, 1358, 1359, 1362, 1363, 1364, 1366, 1367, 1370, 1376, 1379, 1380, 1387, 1389, 1399, 1412, 1418, 1419, 1420, 1423, 1427, 1428, 1430, 1431, 1432, 1441, 1445, 1448, 1452, 1458, 1460, 1461, 1464, 1471, 1473, 1474, 1475, 1487, 1493, 1494, 1496, 1497, 1499, 1504, 1505, 1509, 1511, 1515, 1519, 1526, 1529, 1531, 1533, 1542, 1544, 1547, 1556, 1566, 1567, 1571, 1574, 1577, 1581, 1586, 1593, 1596, 1601, 1615, 1621, 1625, 1643, 1657, 1658, 1675, 1691, 1695, 1702, 1705, 1710, 1712, 1713, 1715, 1736, 1738, 1744, 1746, 1749, 1752, 1759, 1760, 1761, 1766, 1767, 1768, 1771, 1772, 1783, 1789, 1800, 2100, 2102, 2103, 2104, 2108, 2110, 2111, 2112, 2117, 2124, 2137, 2141, 2146, 2148, 2150, 2154, 2160, 2162, 2166, 2171, 2172, 2184, 2194, 2196, 2200, 2214, 2217, 2219, 2231, 2232, 2239, 2240, 2243, 2244, 2254, 2255, 2258, 2265, 2272, 2277, 2278, 2285, 2293, 2294, 2299, 2300, 2301, 2307, 2310, 2315, 2323, 2324, 2331, 2332, 2337, 2340, 2343, 2345, 2346, 2347, 2355, 2357, 2361, 2362, 2365, 2369, 2370, 2372, 2377, 2383, 2396, 2399, 2406, 2411, 2412, 2415, 2420, 2425, 2433, 2436, 2439, 2445, 2447, 2448, 2450, 2453, 2460, 2462, 2464, 2465, 2472, 2475, 2478, 2480, 2483, 2485, 2490, 2491, 2494, 2498, 2501, 2505, 2509, 2513, 2525, 2526, 2527, 2537, 2539, 2542, 2543, 2550, 2551, 2552, 2565, 2574, 2575, 2577, 2580, 2585, 2587, 2591, 2600, 2605, 2613, 2625, 2635, 2648, 2650, 2657, 2664, 2673, 2688, 2693, 2700, 2702, 2707, 2713, 2714, 2715, 2717, 2719, 2720, 2730, 2743, 2744, 2748, 2768, 2774, 2777, 2778, 2791, 2794, 2805, 2806, 2812, 2815, 2817, 2818, 2825, 2841, 2842, 2846, 2847, 2853, 2857, 2858, 2863, 2865, 2866, 2868, 2875, 2876, 2890, 2892, 2900, 2902, 2905, 2906, 2916, 2929, 2931, 2942, 2943, 2945, 2948, 2950, 2994, 3005, 3007, 3008, 3014, 3015, 3016, 3021, 3028, 3029, 3035, 3045, 3051, 3056, 3058, 3063, 3064, 3065, 3071, 3072, 3076, 3077, 3080, 3083, 3088, 3097, 3098, 3106, 3117, 3121, 3122, 3126, 3127, 3129, 3130, 3131, 3140, 3141, 3147, 3166, 3175, 3179, 3181, 3183, 3184, 3185, 3195, 3197, 3198, 3211, 3213, 3222, 3223, 3225, 3234, 3250, 3255, 3256, 3259, 3262, 3270, 3294, 3295, 3296, 3303, 3304, 3319, 3323, 3326, 3335, 3347, 3348, 3350, 3351, 3352, 3353, 3364, 3368, 3373, 3378, 3382, 3392, 3397, 3400, 3426, 3428, 3432, 3433, 3446, 3447, 3449, 3452, 3457, 3459, 3462, 3464, 3470, 3472, 3480, 3481, 3490, 3497, 3501, 3502, 3504, 3529, 3537, 3554, 3562, 3566, 3567, 3569, 3572, 3574, 3575, 3582, 3588, 3595, 3601, 3602, 3603, 3606, 3609, 3617, 3618, 3621, 3629, 3637, 3651, 3677, 3685, 3687, 3688, 3694, 3701, 3707, 3708, 3710, 3711, 3720, 3733, 3737, 3742, 3757, 3765, 3769, 3775, 3777, 3782, 3788, 3798, 3800, 3803, 3804, 3805, 3812, 3816, 3819, 3824, 3826, 3831, 3838, 3840, 3848, 3852, 3855, 3861, 3865, 3887, 3894, 3895, 3897, 3905, 3911, 3913, 3917, 3920, 3924, 3926, 3927, 3930, 3932, 3946, 3951, 3952, 3966, 3967, 3971, 3975, 3977, 3980, 3992, 3994, 4005, 4006, 4020, 4021, 4023, 4025, 4038, 4042, 4046, 4048, 4061, 4063, 4066, 4067, 4073, 4081, 4088, 4093, 4104, 4105, 4115, 4129, 4141, 4142, 4151, 4156, 4157, 4162, 4167, 4171, 4185, 4194, 4195, 4198, 4202, 4206, 4210, 4220, 4227, 4234, 4235, 4237, 4243, 4247, 4251, 4257, 4258, 4263, 4270, 4283, 4287, 4296, 4299, 4304, 4307, 4323, 4324, 4328, 4334, 4342, 4359, 4375, 4376, 4377, 4388, 4397, 4407, 4409, 4416, 4428, 4430, 4438, 4443, 4450, 4452, 4455, 4457, 4458, 4460, 4465, 4476, 4482, 4488, 4492, 4493, 4497, 4502, 4505, 4506, 4507, 4511, 4515, 4518, 4537, 4543, 4549, 4551, 4553, 4558, 4560, 4566, 4567, 4583, 4584, 4585, 4596] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11328/2316265457.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mskf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"TRAIN:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"TEST:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mX_train_fold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_fold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextracted_spam_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextracted_spam_tets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0my_train_fold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_fold\u001b[0m \u001b[1;33m=\u001b[0m     \u001b[0mscaled_3h_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaled_3h_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\_School_Software\\anaconda3\\envs\\cs4821\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    964\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 966\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    967\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\_School_Software\\anaconda3\\envs\\cs4821\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_get_with\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    999\u001b[0m             \u001b[1;31m#  (i.e. self.iloc) or label-based (i.e. self.loc)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1000\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_fallback_to_positional\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1001\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1002\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1003\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\_School_Software\\anaconda3\\envs\\cs4821\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    929\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    930\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 931\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    932\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\_School_Software\\anaconda3\\envs\\cs4821\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1151\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1153\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1155\u001b[0m             \u001b[1;31m# nested tuple slicing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\_School_Software\\anaconda3\\envs\\cs4821\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1091\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1092\u001b[0m         \u001b[1;31m# A collection of keys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1093\u001b[1;33m         \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1094\u001b[0m         return self.obj._reindex_with_indexers(\n\u001b[0;32m   1095\u001b[0m             \u001b[1;33m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\_School_Software\\anaconda3\\envs\\cs4821\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1312\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1314\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m         if needs_i8_conversion(ax.dtype) or isinstance(\n",
      "\u001b[1;32mD:\\_School_Software\\anaconda3\\envs\\cs4821\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis)\u001b[0m\n\u001b[0;32m   1375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1376\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1377\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{not_found} not in index\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1378\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '[182, 185, 189, 192, 195, 202, 203, 214, 217, 218, 220, 221, 223, 224, 227, 241, 245, 246, 248, 252, 253, 263, 269, 271, 283, 286, 291, 294, 298, 302, 304, 308, 311, 314, 325, 326, 333, 345, 347, 348, 352, 378, 379, 381, 383, 402, 405, 406, 408, 410, 415, 429, 453, 462, 463, 465, 470, 480, 481, 485, 487, 489, 491, 496, 499, 500, 501, 502, 507, 514, 520, 521, 526, 528, 530, 531, 533, 534, 536, 541, 543, 545, 548, 553, 555, 556, 559, 562, 567, 569, 575, 576, 578, 581, 582, 584, 599, 619, 620, 621, 622, 629, 634, 636, 638, 639, 648, 651, 661, 666, 667, 668, 675, 678, 680, 683, 684, 685, 690, 704, 708, 712, 716, 720, 727, 731, 735, 748, 751, 773, 775, 776, 780, 788, 799, 803, 806, 809, 812, 817, 825, 829, 831, 836, 842, 847, 849, 854, 861, 866, 867, 872, 873, 878, 882, 883, 888, 891, 895, 896, 898, 900, 906, 910, 917, 918, 927, 933, 938, 939, 942, 949, 962, 965, 971, 976, 977, 979, 980, 982, 991, 995, 1001, 1002, 1005, 1009, 1011, 1012, 1021, 1022, 1043, 1051, 1065, 1068, 1069, 1073, 1077, 1082, 1084, 1085, 1091, 1095, 1098, 1104, 1109, 1114, 1115, 1116, 1118, 1127, 1141, 1144, 1160, 1161, 1163, 1170, 1172, 1176, 1177, 1190, 1196, 1202, 1203, 1206, 1220, 1230, 1232, 1237, 1239, 1246, 1256, 1259, 1261, 1262, 1267, 1271, 1272, 1273, 1275, 1281, 1290, 1299, 1300, 1303, 1319, 1324, 1327, 1328, 1329, 1336, 1343, 1351, 1357, 1358, 1359, 1362, 1363, 1364, 1366, 1367, 1370, 1376, 1379, 1380, 1387, 1389, 1399, 1412, 1418, 1419, 1420, 1423, 1427, 1428, 1430, 1431, 1432, 1441, 1445, 1448, 1452, 1458, 1460, 1461, 1464, 1471, 1473, 1474, 1475, 1487, 1493, 1494, 1496, 1497, 1499, 1504, 1505, 1509, 1511, 1515, 1519, 1526, 1529, 1531, 1533, 1542, 1544, 1547, 1556, 1566, 1567, 1571, 1574, 1577, 1581, 1586, 1593, 1596, 1601, 1615, 1621, 1625, 1643, 1657, 1658, 1675, 1691, 1695, 1702, 1705, 1710, 1712, 1713, 1715, 1736, 1738, 1744, 1746, 1749, 1752, 1759, 1760, 1761, 1766, 1767, 1768, 1771, 1772, 1783, 1789, 1800, 2100, 2102, 2103, 2104, 2108, 2110, 2111, 2112, 2117, 2124, 2137, 2141, 2146, 2148, 2150, 2154, 2160, 2162, 2166, 2171, 2172, 2184, 2194, 2196, 2200, 2214, 2217, 2219, 2231, 2232, 2239, 2240, 2243, 2244, 2254, 2255, 2258, 2265, 2272, 2277, 2278, 2285, 2293, 2294, 2299, 2300, 2301, 2307, 2310, 2315, 2323, 2324, 2331, 2332, 2337, 2340, 2343, 2345, 2346, 2347, 2355, 2357, 2361, 2362, 2365, 2369, 2370, 2372, 2377, 2383, 2396, 2399, 2406, 2411, 2412, 2415, 2420, 2425, 2433, 2436, 2439, 2445, 2447, 2448, 2450, 2453, 2460, 2462, 2464, 2465, 2472, 2475, 2478, 2480, 2483, 2485, 2490, 2491, 2494, 2498, 2501, 2505, 2509, 2513, 2525, 2526, 2527, 2537, 2539, 2542, 2543, 2550, 2551, 2552, 2565, 2574, 2575, 2577, 2580, 2585, 2587, 2591, 2600, 2605, 2613, 2625, 2635, 2648, 2650, 2657, 2664, 2673, 2688, 2693, 2700, 2702, 2707, 2713, 2714, 2715, 2717, 2719, 2720, 2730, 2743, 2744, 2748, 2768, 2774, 2777, 2778, 2791, 2794, 2805, 2806, 2812, 2815, 2817, 2818, 2825, 2841, 2842, 2846, 2847, 2853, 2857, 2858, 2863, 2865, 2866, 2868, 2875, 2876, 2890, 2892, 2900, 2902, 2905, 2906, 2916, 2929, 2931, 2942, 2943, 2945, 2948, 2950, 2994, 3005, 3007, 3008, 3014, 3015, 3016, 3021, 3028, 3029, 3035, 3045, 3051, 3056, 3058, 3063, 3064, 3065, 3071, 3072, 3076, 3077, 3080, 3083, 3088, 3097, 3098, 3106, 3117, 3121, 3122, 3126, 3127, 3129, 3130, 3131, 3140, 3141, 3147, 3166, 3175, 3179, 3181, 3183, 3184, 3185, 3195, 3197, 3198, 3211, 3213, 3222, 3223, 3225, 3234, 3250, 3255, 3256, 3259, 3262, 3270, 3294, 3295, 3296, 3303, 3304, 3319, 3323, 3326, 3335, 3347, 3348, 3350, 3351, 3352, 3353, 3364, 3368, 3373, 3378, 3382, 3392, 3397, 3400, 3426, 3428, 3432, 3433, 3446, 3447, 3449, 3452, 3457, 3459, 3462, 3464, 3470, 3472, 3480, 3481, 3490, 3497, 3501, 3502, 3504, 3529, 3537, 3554, 3562, 3566, 3567, 3569, 3572, 3574, 3575, 3582, 3588, 3595, 3601, 3602, 3603, 3606, 3609, 3617, 3618, 3621, 3629, 3637, 3651, 3677, 3685, 3687, 3688, 3694, 3701, 3707, 3708, 3710, 3711, 3720, 3733, 3737, 3742, 3757, 3765, 3769, 3775, 3777, 3782, 3788, 3798, 3800, 3803, 3804, 3805, 3812, 3816, 3819, 3824, 3826, 3831, 3838, 3840, 3848, 3852, 3855, 3861, 3865, 3887, 3894, 3895, 3897, 3905, 3911, 3913, 3917, 3920, 3924, 3926, 3927, 3930, 3932, 3946, 3951, 3952, 3966, 3967, 3971, 3975, 3977, 3980, 3992, 3994, 4005, 4006, 4020, 4021, 4023, 4025, 4038, 4042, 4046, 4048, 4061, 4063, 4066, 4067, 4073, 4081, 4088, 4093, 4104, 4105, 4115, 4129, 4141, 4142, 4151, 4156, 4157, 4162, 4167, 4171, 4185, 4194, 4195, 4198, 4202, 4206, 4210, 4220, 4227, 4234, 4235, 4237, 4243, 4247, 4251, 4257, 4258, 4263, 4270, 4283, 4287, 4296, 4299, 4304, 4307, 4323, 4324, 4328, 4334, 4342, 4359, 4375, 4376, 4377, 4388, 4397, 4407, 4409, 4416, 4428, 4430, 4438, 4443, 4450, 4452, 4455, 4457, 4458, 4460, 4465, 4476, 4482, 4488, 4492, 4493, 4497, 4502, 4505, 4506, 4507, 4511, 4515, 4518, 4537, 4543, 4549, 4551, 4553, 4558, 4560, 4566, 4567, 4583, 4584, 4585, 4596] not in index'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score,StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, random_state=None)\n",
    "\n",
    "for train_index, test_index in skf.split(XH, YH):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train_fold, X_test_fold = extracted_spam_train[train_index], extracted_spam_tets[test_index]\n",
    "    y_train_fold, y_test_fold = scaled_3h_train[train_index], scaled_3h_test[test_index]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515208ca",
   "metadata": {},
   "source": [
    "#### 3.i.2: \n",
    "You should train each of the models on the training set and evaluate each model on the validation set. You will examine cost parameters of [10^−2, 10^−1, 1, 10] for both the linear and RBF kernel. \n",
    "Report out in a table/dataframe for each parameter combination (cost and kernel) the following mean performances on the validation set: accuracy, precision, and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a70f85f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Model\n",
      "       Accuracy  Precision    Reacll\n",
      "0.01   0.578719   0.307692  0.010444\n",
      "0.10   0.840391   0.906897  0.686684\n",
      "1.00   0.891422   0.912536  0.817232\n",
      "10.00  0.915309   0.913279  0.879896\n",
      "\n",
      "\n",
      "RBF Model\n",
      "       Accuracy  Precision    Reacll\n",
      "0.01   0.792617   0.932432  0.540470\n",
      "0.10   0.887079   0.926606  0.791123\n",
      "1.00   0.929425   0.934426  0.892950\n",
      "10.00  0.934853   0.940054  0.900783\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "\n",
    "vals=[0.01, 0.1, 1, 10]\n",
    "\n",
    "prec=[]\n",
    "acc=[]\n",
    "rec=[]\n",
    "\n",
    "prec1=[]\n",
    "acc1=[]\n",
    "rec1=[]\n",
    "\n",
    "for cost in vals:\n",
    "    #create SVM with liner kernal and cost 'C'\n",
    "    clf = svm.SVC(kernel = 'linear', C = cost)\n",
    "\n",
    "    #fit(X,y) on training data\n",
    "    clf.fit(scaled_3h_train, extracted_spam_train)\n",
    "\n",
    "    #predict\n",
    "    curr_predict=clf.predict(scaled_3h_test)\n",
    "\n",
    "    acc.append(accuracy_score(extracted_spam_test, curr_predict))\n",
    "\n",
    "    prec.append(precision_score(extracted_spam_test, curr_predict))\n",
    "    \n",
    "    rec.append(recall_score(extracted_spam_test, curr_predict))\n",
    "\n",
    "for cost in vals:\n",
    "    #create SVM with liner kernal and cost 'C'\n",
    "    clf = svm.SVC(kernel = 'rbf', C = cost)\n",
    "\n",
    "    #fit(X,y) on training data\n",
    "    clf.fit(scaled_3h_train, extracted_spam_train)\n",
    "\n",
    "    #predict\n",
    "    curr_predict=clf.predict(scaled_3h_test)\n",
    "\n",
    "    acc1.append(accuracy_score(extracted_spam_test, curr_predict))\n",
    "\n",
    "    prec1.append(precision_score(extracted_spam_test, curr_predict))\n",
    "    \n",
    "    rec1.append(recall_score(extracted_spam_test, curr_predict))    \n",
    "\n",
    "    \n",
    "#first dataframe for linear model\n",
    "data = {\n",
    "  \"Accuracy\": acc,\n",
    "  \"Precision\": prec,\n",
    "    \"Reacll\": rec\n",
    "}\n",
    "df = pd.DataFrame(data, index = vals)\n",
    "print(\"Linear Model\")\n",
    "print(df)\n",
    "\n",
    "#second dataframe for rbf model\n",
    "data1 = {\n",
    "  \"Accuracy\": acc1,\n",
    "  \"Precision\": prec1,\n",
    "    \"Reacll\": rec1\n",
    "}\n",
    "df2 = pd.DataFrame(data1, index = vals)\n",
    "print(\"\\n\\nRBF Model\")\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1588e5fc",
   "metadata": {},
   "source": [
    "#### 3.i.3: \n",
    "Report the best parameter combination (cost and kernel) using accuracy\n",
    "as the criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3e07f1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameter of cost and kernal using accuracy as a measure are\n",
      "Kernal: RBF, cost = 0.934853\n"
     ]
    }
   ],
   "source": [
    "lin=[vals,acc]\n",
    "rbf=[vals,acc1]\n",
    "\n",
    "#find max value\n",
    "temp = np.max(lin[1])\n",
    "temp2 = np.max(rbf[1])\n",
    "\n",
    "#find location \n",
    "locLin = int(np.asarray(np.where(temp == lin[1])))\n",
    "locRbf = int(np.asarray(np.where(temp2 == rbf[1])))\n",
    "\n",
    "#find cost\n",
    "lins=[temp,locLin,vals[locLin]]\n",
    "rbfs=[temp2,locRbf,vals[locRbf]]\n",
    "\n",
    "print(\"The best parameter of cost and kernal using accuracy as a measure are\")\n",
    "if(lins[0] > rbfs[0]):\n",
    "    print(\"Kernal: Linear, cost = {0:0.4f}\".format(lins[0]))\n",
    "else:\n",
    "    print(\"Kernal: RBF, cost = {0:04f}\".format(rbfs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054f0f58",
   "metadata": {},
   "source": [
    "#### 3.i.4: \n",
    "Retrain a model with the best parameters on train+validation and evaluate it on the testing data. Report this model’s accuracy, precision and recall.\n",
    "Helpful Functions: Python- SVC from sklearn.svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b95da574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrained model with best parameters from above (RBF, C=10)\n",
      "mean accuracy 0.9349\n",
      "mean precision 0.9401\n",
      "mean recal 0.9008\n"
     ]
    }
   ],
   "source": [
    "acc2=[]\n",
    "prec2=[]\n",
    "rec2=[]\n",
    "\n",
    "clf = svm.SVC(kernel = 'rbf', C = 10)\n",
    "\n",
    "#fit(X,y) on training data\n",
    "clf.fit(scaled_3h_train, extracted_spam_train)\n",
    "\n",
    "#predict\n",
    "curr_predict=clf.predict(scaled_3h_test)\n",
    "\n",
    "acc2.append(accuracy_score(extracted_spam_test, curr_predict))\n",
    "\n",
    "prec2.append(precision_score(extracted_spam_test, curr_predict))\n",
    " \n",
    "rec2.append(recall_score(extracted_spam_test, curr_predict))   \n",
    "#print('Acc: ', acc)\n",
    "#print('Prec: ', prec)\n",
    "#print('Rec: ',rec)\n",
    "\n",
    "print(\"Retrained model with best parameters from above (RBF, C=10)\")\n",
    "print('mean accuracy {0:0.04f}' .format(np.mean(acc2)))\n",
    "\n",
    "print('mean precision {0:0.04f}' .format(np.mean(prec2)))\n",
    "\n",
    "print('mean recal {0:0.04f}' .format(np.mean(rec2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c588d1fc",
   "metadata": {},
   "source": [
    "### 3.j: Ensemble Methods - Part 1\n",
    "Learn boosting modesl to predict spam using 10-fold cross-validation on the train+validaion data to select the best parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa447b67",
   "metadata": {},
   "source": [
    "#### 3.j.i: \n",
    "You will use the same method as in Q3(i)i to set up and perform the cross-validation by hand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540cb0df",
   "metadata": {},
   "source": [
    "#### Used the data that is in Q3(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533c7373",
   "metadata": {},
   "source": [
    "#### 3.j.ii:\n",
    "Train AdaBoost models with the number of decision stumps to be [10, 25,\n",
    "50, 100]. Report out in a table/datafram the mean F1 score for each parameter value.\n",
    "Functions: Python - AdaBoostClassifier from sklearn.ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "01711f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.913075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.912998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.922503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.926137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Mean F1 Score\n",
       "10        0.913075\n",
       "25        0.912998\n",
       "50        0.922503\n",
       "100       0.926137"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "d_stumps = [10, 25, 50, 100]\n",
    "\n",
    "f_score=[]\n",
    "f_score_means=[]\n",
    "\n",
    "for ds in d_stumps:\n",
    "    #boost with d_stump values\n",
    "    clf = AdaBoostClassifier(n_estimators = ds, random_state = 0)\n",
    "\n",
    "    #fit(X,y) on training data\n",
    "    clf.fit(scaled_3h_train, extracted_spam_train)\n",
    "\n",
    "    #predict\n",
    "    curr_predict = clf.predict(scaled_3h_test)\n",
    "\n",
    "    #store current f_score\n",
    "    f_score.append(f1_score(extracted_spam_test, curr_predict, average=None))\n",
    "\n",
    "#loop through each array in f_score, calcualte the mean and store in f_score_means\n",
    "for i in f_score:\n",
    "    f_score_means.append(np.mean(i))\n",
    "\n",
    "#create dataframe of mean f1 scores\n",
    "f_data = {\"Mean F1 Score\": f_score_means}\n",
    "f1_df = pd.DataFrame(f_data, index = d_stumps)\n",
    "\n",
    "f1_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2be68f3",
   "metadata": {},
   "source": [
    "#### 3.j.iii\n",
    "Report out the best parameter value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "fcfbac37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameter value is:\n",
      "Decision stump value of: 100 and a mean F1 score of 0.926137\n"
     ]
    }
   ],
   "source": [
    "foo = int(np.asarray(np.where(np.max(f_score_means)==f_score_means)))\n",
    "print(\"The best parameter value is:\")\n",
    "print(\"Decision stump value of: \" + str(d_stumps[foo]) +\" and a mean F1 score of {0:004f}\".format(np.max(f_score_means)) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e8547d",
   "metadata": {},
   "source": [
    "#### 3.j.iv:\n",
    "Retrain a model with the best parameters on train+validation and evaluate it on the testing data. Report this model’s F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "89858422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9261373578302712\n"
     ]
    }
   ],
   "source": [
    "f_score2=[]\n",
    "#boost with d_stump values\n",
    "clf = AdaBoostClassifier(n_estimators = 100, random_state = 0)\n",
    "\n",
    "#fit(X,y) on training data\n",
    "clf.fit(scaled_3h_train, extracted_spam_train)\n",
    "\n",
    "#predict\n",
    "curr_predict = clf.predict(scaled_3h_test)\n",
    "\n",
    "#store current f_score\n",
    "f_score2.append(f1_score(extracted_spam_test, curr_predict, average=None))\n",
    "\n",
    "print(np.mean(f_score2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013fdc5a",
   "metadata": {},
   "source": [
    "### 3.k:\n",
    "Model Selection and Evaluation: Grid Search with Cross-Validation-GridSearchCV\n",
    "\n",
    "We will again perform a GridSearch with cross-validation on the train+validation set, but here we will make use of the functions that do the cross-validation internally. \n",
    "\n",
    "Functions: Python - GridSearchCV from sklearn.model selection. \n",
    "\n",
    "Here again, start by splitting out the test set with 20% of the data. \n",
    "\n",
    "Helpful functions: Python -train test split from sklearn.model selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0762bc03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23082f5e",
   "metadata": {},
   "source": [
    "### 3.l: Ensemble Methods - Part 2\n",
    "Let's examine bagging ensamble approaches for predicting spam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ec078b",
   "metadata": {},
   "source": [
    "#### 3.l.i:\n",
    "The remaining train+validation set, from Q3(k), will be using 10-fold cross-validation with the GridSearchCV functions.\n",
    "Functions: Python - GridSearchCV from sklearn.model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c186bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01d8e9bb",
   "metadata": {},
   "source": [
    "#### 3.l.ii: \n",
    "Train Random Forest models with parameters of the maximum number of\n",
    "features [2, 4, 8, 16] and number of estimators of [25, 50, 100]. \n",
    "Report the mean AUC on validation set for the different parameter combinations.\n",
    "Functions: Python - RandomForestClassifier from sklearn.ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35569a57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a25e8bb",
   "metadata": {},
   "source": [
    "#### 3.l.iii:\n",
    "Report out the best parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8a47c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45a67e32",
   "metadata": {},
   "source": [
    "#### 3.l.iv: \n",
    "Retrain a model with the best parameters on train+validation and evaluate it on the testing data. Resport this model's AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e14a877",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fbbffd6d",
   "metadata": {},
   "source": [
    "## (Question 4) NBA Baskeball - Using Pipelines / Workflows\n",
    "For this problem you will use a data set of 9,958 NBA basketball games (the 2016-2019 seasons).\n",
    "This dataset of the games and the associated properties has been collected from NBA website\n",
    "API - https://www.nba.com/. You will use this data set with the goal to predict whether\n",
    "a team will win a game"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92780a94",
   "metadata": {},
   "source": [
    "The data set variables consist of the following:\n",
    "- SEASON ID, GAME ID, GAME DATE - variables that are to be ignored for prediction, but here\n",
    "to recognize the individual samples\n",
    "- TEAM A, TEAM B, MATCHUP - variables describing the two teams in a game.\n",
    "- WON - This is the target / class feature to be predicted.\n",
    "The remaining variables are predictor variables for the models. They come in pairs\n",
    "“* DIFF” and “* A” reporting the given statistic as the difference between Team A and\n",
    "Team B and the statistic itself for Team A.\n",
    "- FG PCT DIFF, FG PCT A - field goal percentage.\n",
    "- FGM DIFF, FGM A - number of field goals made.\n",
    "- FG3 PCT DIFF, FG3 PCT A - percentage of 3-point shots made.\n",
    "- FG3M DIFF, FG3M A - number of 3-point shots made.\n",
    "- FT PCT DIFF, FT PCT A - percentage of free throws made.\n",
    "- FTM DIFF, FTM A - number of free throws made.\n",
    "- REB DIFF, REB A - number of rebounds.\n",
    "- AST DIFF, AST A - number of assists.\n",
    "- STL DIFF, STL A - number of steals.\n",
    "- TOV DIFF, TOV A - number of turnovers.\n",
    "- PF DIFF, PF A - number of personal fouls.\n",
    "\n",
    "For this question, you will make use of the pipeline and workflow functions to simplify the code needed to select and evaluate multiple methods.\n",
    "Functions: Python - make pipeline in sklearn.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bae8545",
   "metadata": {},
   "source": [
    "### 4.a: \n",
    "Load in the NBA data.\n",
    "There are a few missing values, remove any rows that contains missing values. How many samples remain?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21860c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEASON_ID = \"season_id\"\n",
    "GAME_ID = 'game_id'\n",
    "GAME_DATE = 'game_date'\n",
    "\n",
    "TEAM_A = 'team_a'\n",
    "TEAM_B = 'team_b'\n",
    "MATCHUP = 'matchup'\n",
    "\n",
    "WON = 'won'\n",
    "\n",
    "FIELD_GOAL_PERC_DIFF = 'field_goal_perc_diff'\n",
    "FIELD_GOAL_PERC_A = 'field_goal_perc_A'\n",
    "\n",
    "FIELD_GOAL_MADE_DIFF = 'field_goal_made_diff'\n",
    "FIELD_GOAL_MADE_A = 'field_goal_made_A'\n",
    "\n",
    "THREE_POINTERS_MADE_PERC_DIFF = 'three_pointers_made_perc_diff'\n",
    "THREE_POINTERS_MADE_PERC_A = 'three_pointers_made_perc_A'\n",
    "\n",
    "THREE_POINTERS_MADE_DIFF = 'three_pointers_made_diff'\n",
    "THREE_POINTERS_MADE_A = 'three_pointers_made_A'\n",
    "\n",
    "FREE_THROWS_MADE_PERC_DIFF = 'free_throws_made_perc_diff'\n",
    "FREE_THROWS_MADE_PERC_A = 'free_throws_made_perc_A'\n",
    "\n",
    "FREE_THROWS_MADE_DIFF = 'free_throws_made_diff'\n",
    "FREE_THROWS_MADE_A = 'free_throws_made_A'\n",
    "\n",
    "REBOUNDS_DIFF = 'rebounds_diff'\n",
    "REBOUNDS_A = 'rebounds_A'\n",
    "\n",
    "ASSISTS_DIFF = 'assists_diff'\n",
    "ASSISTS_A = 'assists_A'\n",
    "\n",
    "STEALS_DIFF = 'steals_diff'\n",
    "STEALS_A = 'steals_A'\n",
    "\n",
    "TURNOVERS_DIFF = 'turnovers_diff'\n",
    "TURNOVERS_A = 'turnovers_A'\n",
    "\n",
    "PERSONAL_FOULS_DIFF = 'personal_fouls_diff'\n",
    "PERSONAL_FOULS_A = 'personal_fouls_A'\n",
    "\n",
    "# The following two data structures were generated automatically by a python script\n",
    "NBA_COLUMNS = [\n",
    "\tSEASON_ID,\n",
    "\tGAME_ID,\n",
    "\tGAME_DATE,\n",
    "\tTEAM_A,\n",
    "\tTEAM_B,\n",
    "\tMATCHUP,\n",
    "\tWON,\n",
    "\tFIELD_GOAL_PERC_DIFF,\n",
    "\tFIELD_GOAL_PERC_A,\n",
    "\tFIELD_GOAL_MADE_DIFF,\n",
    "\tFIELD_GOAL_MADE_A,\n",
    "\tTHREE_POINTERS_MADE_PERC_DIFF,\n",
    "\tTHREE_POINTERS_MADE_PERC_A,\n",
    "\tTHREE_POINTERS_MADE_DIFF,\n",
    "\tTHREE_POINTERS_MADE_A,\n",
    "\tFREE_THROWS_MADE_PERC_DIFF,\n",
    "\tFREE_THROWS_MADE_PERC_A,\n",
    "\tFREE_THROWS_MADE_DIFF,\n",
    "\tFREE_THROWS_MADE_A,\n",
    "\tREBOUNDS_DIFF,\n",
    "\tREBOUNDS_A,\n",
    "\tASSISTS_DIFF,\n",
    "\tASSISTS_A,\n",
    "\tSTEALS_DIFF,\n",
    "\tSTEALS_A,\n",
    "\tTURNOVERS_DIFF,\n",
    "\tTURNOVERS_A,\n",
    "\tPERSONAL_FOULS_DIFF,\n",
    "\tPERSONAL_FOULS_A,\n",
    "]\n",
    "\n",
    "NBA_CLEAN_NAMES = {\n",
    "\tSEASON_ID: \"Season Id\",\n",
    "\tGAME_ID: \"Game Id\",\n",
    "\tGAME_DATE: \"Game Date\",\n",
    "\tTEAM_A: \"Team A\",\n",
    "\tTEAM_B: \"Team B\",\n",
    "\tMATCHUP: \"Matchup\",\n",
    "\tWON: \"Won\",\n",
    "\tFIELD_GOAL_PERC_DIFF: \"Field Goal % Difference\",\n",
    "\tFIELD_GOAL_PERC_A: \"A Team Field Goal %\",\n",
    "\tFIELD_GOAL_MADE_DIFF: \"Field Goal Difference\",\n",
    "\tFIELD_GOAL_MADE_A: \"A Team Field Goal\",\n",
    "\tTHREE_POINTERS_MADE_PERC_DIFF: \"Three Pointers % Difference\",\n",
    "\tTHREE_POINTERS_MADE_PERC_A: \"A Team Three Pointers %\",\n",
    "\tTHREE_POINTERS_MADE_DIFF: \"Three Pointers Difference\",\n",
    "\tTHREE_POINTERS_MADE_A: \"A Team Three Pointers\",\n",
    "\tFREE_THROWS_MADE_PERC_DIFF: \"Free Throws % Difference\",\n",
    "\tFREE_THROWS_MADE_PERC_A: \"A Team Free Throws %\",\n",
    "\tFREE_THROWS_MADE_DIFF: \"Free Throws Difference\",\n",
    "\tFREE_THROWS_MADE_A: \"A Team Free Throws\",\n",
    "\tREBOUNDS_DIFF: \"Rebounds Difference\",\n",
    "\tREBOUNDS_A: \"A Team Rebounds\",\n",
    "\tASSISTS_DIFF: \"Assists Difference\",\n",
    "\tASSISTS_A: \"A Team Assists\",\n",
    "\tSTEALS_DIFF: \"Steals Difference\",\n",
    "\tSTEALS_A: \"A Team Steals\",\n",
    "\tTURNOVERS_DIFF: \"Turnovers Difference\",\n",
    "\tTURNOVERS_A: \"A Team Turnovers\",\n",
    "\tPERSONAL_FOULS_DIFF: \"Personal Fouls Difference\",\n",
    "\tPERSONAL_FOULS_A: \"A Team Personal Fouls\",\n",
    "}\n",
    "\n",
    "NBA_CLEAN_COLUMNS = [NBA_CLEAN_NAMES[var] for var in NBA_COLUMNS]\n",
    "\n",
    "\n",
    "NBA_CSV = 'nba.csv'\n",
    "NBA_DATA = pd.read_csv(NBA_CSV, names=NBA_CLEAN_COLUMNS)\n",
    "# First row is just col titles, garbage in our case\n",
    "NBA_DATA = NBA_DATA[1:]\n",
    "\n",
    "# How many samples do we have?\n",
    "num_samples = len(NBA_DATA.values)\n",
    "\n",
    "# Purge samples containing null values\n",
    "\n",
    "# Make a set of rows to delete\n",
    "ROWS_MARKED_FOR_DELETION = set()\n",
    "\n",
    "samples_removed = 0\n",
    "\n",
    "# Find indeces that should be removed, loop through all the rows in the table\n",
    "NBA_DATA.reset_index()\n",
    "for i, match in NBA_DATA.iterrows():\n",
    "    if any(match.isnull()):\n",
    "        ROWS_MARKED_FOR_DELETION.add(i)\n",
    "\n",
    "for ind in sorted(ROWS_MARKED_FOR_DELETION, reverse=True):\n",
    "    NBA_DATA = NBA_DATA.drop(index=ind)\n",
    "    samples_removed += 1\n",
    "\n",
    "samples_remaining = len(NBA_DATA.values)\n",
    "\n",
    "print(f\"After removing {samples_removed} samples, {samples_remaining} remain.\")\n",
    "\n",
    "NBA_DATA.reset_index()\n",
    "NBA_DATA.head(n=len(NBA_DATA.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e723e7",
   "metadata": {},
   "source": [
    "### 4.b: \n",
    "You will not use the following columns for your predictors: SEASON ID, GAME ID, GAME DATE, TEAM A, TEAM B, MATCHUP. \n",
    "The WON column will become what you are trying to predict and the remaining columns your input variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f96585",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIMPLE_NBA_DATA = NBA_DATA.copy()\n",
    "\n",
    "# Remove columns we don't need\n",
    "cols_to_remove = [\n",
    "\tNBA_CLEAN_NAMES[SEASON_ID],\n",
    "\tNBA_CLEAN_NAMES[GAME_ID],\n",
    "\tNBA_CLEAN_NAMES[GAME_DATE],\n",
    "\tNBA_CLEAN_NAMES[TEAM_A],\n",
    "\tNBA_CLEAN_NAMES[TEAM_B],\n",
    "\tNBA_CLEAN_NAMES[MATCHUP],\n",
    "]\n",
    "\n",
    "# Drop the columns\n",
    "SIMPLE_NBA_DATA = SIMPLE_NBA_DATA.drop(columns=cols_to_remove)\n",
    "SIMPLE_NBA_DATA.head(n=len(SIMPLE_NBA_DATA.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e232da4e",
   "metadata": {},
   "source": [
    "### 4.c: \n",
    "Split off a random 20% of the data for testing. Set the seed for the random generator to ”5”.\n",
    "Python - random state and R - set.seed(5).\n",
    "Helpful Python - train test split from sklearn.model selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b04a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some constants that affect how our train test split functions\n",
    "PERCENT_DATA_WANTED = 0.20\n",
    "SEED = 5\n",
    "\n",
    "# Split off 20% of the data\n",
    "nba_train_data, nba_test_data = train_test_split(SIMPLE_NBA_DATA, test_size=PERCENT_DATA_WANTED, random_state=SEED)\n",
    "\n",
    "nba_train_data.head(n=5)\n",
    "\n",
    "# Extract the won column from the data, this will be used to check predictions not make them\n",
    "extracted_won_train_col = nba_train_data[NBA_CLEAN_NAMES[WON]]\n",
    "extracted_won_test_col = nba_test_data[NBA_CLEAN_NAMES[WON]]\n",
    "\n",
    "extracted_won_train_col = extracted_won_train_col.astype('<U1')\n",
    "extracted_won_test_col = extracted_won_test_col.astype('<U1')\n",
    "\n",
    "print(extracted_won_test_col)\n",
    "\n",
    "# Remove the won column from the data completely\n",
    "nba_train_data = nba_train_data.drop(columns=[NBA_CLEAN_NAMES[WON]])\n",
    "nba_test_data = nba_test_data.drop(columns=[NBA_CLEAN_NAMES[WON]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dde5deb",
   "metadata": {},
   "source": [
    "### 4.d: \n",
    "Parameter Selection\n",
    "\n",
    "You will set up the pipeline/workflow to consider using both MinMax and Standard scaling\n",
    "approaches.\n",
    "You will consider the following four classification methods with the hyper-parameters\n",
    "specified:\n",
    "- KNN with number of neighbors = [3, 7, 11, 15, 19, 23]\n",
    "- DT with a maximum depth of the tree as [3, 5, 10]\n",
    "- SVM with a polynomial kernel with degree = [1, 2, 3, 4] and a RBF kernel and a cost parameter of [0.01, 0.1, 1]\n",
    "- RF with maximum number of features [2, 4, 8] and number of estimators of [25, 50, 100].\n",
    "When selecting the best parameters with the train+validation data use 5-fold cross-validation and use F1 measure to select the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cff1b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Since we are using the MinMax scaler and the Standard scaling, we need to scale the data set for both scalers\n",
    "min_max_scaler = MinMaxScaler()\n",
    "standard_scaler = StandardScaler()\n",
    "\n",
    "# Train the scalers to fit using the training data\n",
    "min_max_scaler.fit(nba_train_data)\n",
    "standard_scaler.fit(nba_train_data)\n",
    "\n",
    "# Now that the scalers are trained, actually transform the data\n",
    "min_max_scaled_training_data = pd.DataFrame(min_max_scaler.transform(nba_train_data))\n",
    "standard_scaled_training_data = pd.DataFrame(standard_scaler.transform(nba_train_data))\n",
    "min_max_scaled_test_data = pd.DataFrame(min_max_scaler.transform(nba_test_data))\n",
    "standard_scaled_test_data = pd.DataFrame(standard_scaler.transform(nba_test_data))\n",
    "\n",
    "# First we are going to do the KNN classification method\n",
    "_KNN = KNeighborsClassifier(n_neighbors=3)  # Pass in default value of 3, doesn't matter since we are just going to override everytime we call\n",
    "\n",
    "# Now for all nearest neighbor values of k given from assignment,\n",
    "K_VALUES_TO_TEST = [3, 7, 11, 15, 19, 23]\n",
    "for k_value in K_VALUES_TO_TEST:\n",
    "\n",
    "\t# Update the neighbor value\n",
    "\t_KNN.n_neighbors = k_value\n",
    "\n",
    "\t# Train the KNN classifier using the scaled training sets to predict the win column\n",
    "\t_KNN.fit(min_max_scaled_training_data, extracted_won_train_col)\n",
    "\n",
    "\t# Create a prediction set\n",
    "\ty_pred_minmax = _KNN.predict(min_max_scaled_test_data)\n",
    "\t# Print the accuracy of the prediction\n",
    "\tminmax_accuracy = metrics.f1_score(extracted_won_test_col, y_pred_minmax, pos_label='1')\n",
    "\n",
    "\t# Now do the same thing for standard scaled data\n",
    "\t_KNN.fit(standard_scaled_training_data, extracted_won_train_col)\n",
    "\ty_pred_standard = _KNN.predict(standard_scaled_test_data)\n",
    "\tstandard_accuracy = metrics.f1_score(extracted_won_test_col, y_pred_standard, pos_label='1')\n",
    "\n",
    "\t# Print the accuracies\n",
    "\tprint(f\"k value: {k_value} Minmax f1: {minmax_accuracy} Standard f1: {standard_accuracy}\")\n",
    "\n",
    "# Next up, decision tree\n",
    "DTC_DEPTHS = [3, 5, 10]\n",
    "_DTC = DecisionTreeClassifier()\n",
    "\n",
    "# Loop through all the depths we want to try\n",
    "for depth_to_test in DTC_DEPTHS:\n",
    "\n",
    "\t# Set the depth\n",
    "\t_DTC.max_depth = depth_to_test\n",
    "\t# Train the classifier using minmax\n",
    "\t_DTC.fit(min_max_scaled_training_data, extracted_won_train_col)\n",
    "\t# Create a prediction set\n",
    "\ty_pred_minmax = _DTC.predict(min_max_scaled_test_data)\n",
    "\t# What was the accuracy?\n",
    "\tminmax_accuracy = metrics.f1_score(extracted_won_test_col, y_pred_minmax, pos_label='1')\n",
    "\n",
    "\t# Same thing for standard\n",
    "\t# Train the classifier using standard\n",
    "\t_DTC.fit(standard_scaled_training_data, extracted_won_train_col)\n",
    "\t# Create a prediction set\n",
    "\ty_pred_standard = _DTC.predict(standard_scaled_test_data)\n",
    "\t# What was the accuracy?\n",
    "\tstandard_accuracy = metrics.f1_score(extracted_won_test_col, y_pred_standard, pos_label='1')\n",
    "\n",
    "\t# Print results\n",
    "\tprint(f\"max depth: {depth_to_test} Minmax f1: {minmax_accuracy} Standard f1: {standard_accuracy}\")\n",
    "\n",
    "# Next SVM\n",
    "POLYNOMIAL_DEGREES = [1, 2, 3, 4]\n",
    "COSTS = [.01, .1, 1]\n",
    "_SVM = SVC()\n",
    "\n",
    "# First try polynomial kernels\n",
    "for poly in POLYNOMIAL_DEGREES:\n",
    "\t# Set the kernel and the polyomial degree\n",
    "\t_SVM.kernel = 'poly'\n",
    "\t_SVM.degree = poly\n",
    "\t# Train the classifier using minmax\n",
    "\t_SVM.fit(min_max_scaled_training_data, extracted_won_train_col)\n",
    "\t# Create a prediction set\n",
    "\ty_pred_minmax = _SVM.predict(min_max_scaled_test_data)\n",
    "\t# What was the accuracy?\n",
    "\tminmax_accuracy = metrics.f1_score(extracted_won_test_col, y_pred_minmax, pos_label='1')\n",
    "\n",
    "\t# Same thing for standard\n",
    "\t# Train the classifier using standard\n",
    "\t_SVM.fit(standard_scaled_training_data, extracted_won_train_col)\n",
    "\t# Create a prediction set\n",
    "\ty_pred_standard = _SVM.predict(standard_scaled_test_data)\n",
    "\t# What was the accuracy?\n",
    "\tstandard_accuracy = metrics.f1_score(extracted_won_test_col, y_pred_standard, pos_label='1')\n",
    "\n",
    "\t# Print results\n",
    "\tprint(f\"polynomial degree: {poly} Minmax f1: {minmax_accuracy} Standard f1: {standard_accuracy}\")\n",
    "\n",
    "# Now the rbf kernels\n",
    "for cost in COSTS:\n",
    "\t# Set the kernel and the cost\n",
    "\t_SVM.kernel = 'rbf'\n",
    "\t_SVM.gamma = cost\n",
    "\t# Train the classifier using minmax\n",
    "\t_SVM.fit(min_max_scaled_training_data, extracted_won_train_col)\n",
    "\t# Create a prediction set\n",
    "\ty_pred_minmax = _SVM.predict(min_max_scaled_test_data)\n",
    "\t# What was the accuracy?\n",
    "\tminmax_accuracy = metrics.f1_score(extracted_won_test_col, y_pred_minmax, pos_label='1')\n",
    "\n",
    "\t# Same thing for standard\n",
    "\t# Train the classifier using standard\n",
    "\t_SVM.fit(standard_scaled_training_data, extracted_won_train_col)\n",
    "\t# Create a prediction set\n",
    "\ty_pred_standard = _SVM.predict(standard_scaled_test_data)\n",
    "\t# What was the accuracy?\n",
    "\tstandard_accuracy = metrics.f1_score(extracted_won_test_col, y_pred_standard, pos_label='1')\n",
    "\n",
    "\t# Print results\n",
    "\tprint(f\"cost: {cost} Minmax f1: {minmax_accuracy} Standard f1: {standard_accuracy}\")\n",
    "\n",
    "# Now the RF\n",
    "FEATURES = [2, 4, 8]\n",
    "ESTIMATORS = [25, 50, 100]\n",
    "_RFC = RandomForestClassifier()\n",
    "\n",
    "for feature, estimator in zip(FEATURES, ESTIMATORS):\n",
    "\t# Set the features and estimators\n",
    "\t_RFC.max_features = feature\n",
    "\t_RFC.n_estimators = estimator\n",
    "\t# Train the classifier using minmax\n",
    "\t_RFC.fit(min_max_scaled_training_data, extracted_won_train_col)\n",
    "\t# Create a prediction set\n",
    "\ty_pred_minmax = _RFC.predict(min_max_scaled_test_data)\n",
    "\t# What was the accuracy?\n",
    "\tminmax_accuracy = metrics.f1_score(extracted_won_test_col, y_pred_minmax, pos_label='1')\n",
    "\n",
    "\t# Same thing for standard\n",
    "\t# Train the classifier using standard\n",
    "\t_RFC.fit(standard_scaled_training_data, extracted_won_train_col)\n",
    "\t# Create a prediction set\n",
    "\ty_pred_standard = _RFC.predict(standard_scaled_test_data)\n",
    "\t# What was the accuracy?\n",
    "\tstandard_accuracy = metrics.f1_score(extracted_won_test_col, y_pred_standard, pos_label='1')\n",
    "\n",
    "\t# Print results\n",
    "\tprint(f\"features/estimators: {feature}/{estimator} Minmax f1: {minmax_accuracy} Standard f1: {standard_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc40d5f",
   "metadata": {},
   "source": [
    "### 4.e: \n",
    "Report Results\n",
    "\n",
    "Once the best parameters for each model are found, retrain a model with those parameters and evaluate the performance on the test set.\n",
    "Report in a table the following information for each model: the model type (KNN, DT, SVM, RF), the best parameters selected, \n",
    "Accuracy, Precision, Recall, F1, AUC on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0d28f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
